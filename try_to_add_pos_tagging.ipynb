{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import json\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_queries_with_lemmatization(path):\n",
    "    f = open(path)\n",
    "    queries = []\n",
    "    tags = []\n",
    "    mystem = Mystem()\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    \n",
    "    for line in f:\n",
    "        tmp = []\n",
    "        tmp_ = []\n",
    "        text = tokenizer.tokenize(line.lower())\n",
    "        text_tagged = nltk.pos_tag(text, lang='rus')\n",
    "        \n",
    "        for i, q in enumerate(text):\n",
    "            if not np.all(np.any(np.array(list(q)).reshape(-1, 1) == np.array(list(punctuation)).reshape(1, -1), axis=1)):\n",
    "                q_ = mystem.lemmatize(q)\n",
    "                tmp.append(\"\".join(q_).split()[0])\n",
    "                tmp_.append(text_tagged[i][1])\n",
    "        queries.append(tmp)\n",
    "        tags.append(tmp_)\n",
    "    f.close()\n",
    "    return (queries, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['сибирский', 'сеть', 'личный', 'кабинет', 'бердск'],\n",
       "  ['1', 'сантим', 'алжир', '1964'],\n",
       "  ['река', 'колыма', 'на', 'карта', 'россия'],\n",
       "  ['ноофен', 'для', 'какой', 'болезнь'],\n",
       "  ['маус', 'хаус', 'спб']],\n",
       " [['A=pl', 'S', 'A=m', 'S', 'S'],\n",
       "  ['NUM=ciph', 'V', 'S', 'NUM=ciph'],\n",
       "  ['S', 'S', 'PR', 'S', 'S'],\n",
       "  ['V', 'PR', 'A-PRO=pl', 'A=f'],\n",
       "  ['NONLEX', 'NONLEX', 'NONLEX']],\n",
       " [['сбербанк', 'в', 'кунцево', 'плаза'],\n",
       "  ['торт', 'дикий', 'вишня'],\n",
       "  ['тася', 'кривун', 'танец', 'на', 'тнт'],\n",
       "  ['рбт', 'ру'],\n",
       "  ['toplü', 'vay', 'sexx']],\n",
       " [['V', 'PR', 'S', 'S'],\n",
       "  ['S', 'A=f', 'S'],\n",
       "  ['S', 'S', 'S', 'PR', 'S'],\n",
       "  ['V', 'S'],\n",
       "  ['NONLEX', 'NONLEX', 'NONLEX']],\n",
       " 51353,\n",
       " 21174)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/requests.uniq.train'\n",
    "train_lem = read_queries_with_lemmatization(path)\n",
    "path = 'data/requests.uniq.test'\n",
    "test_lem = read_queries_with_lemmatization(path)\n",
    "train_lem[0][:5], train_lem[1][:5], test_lem[0][:5], test_lem[1][:5], len(train_lem[0]), len(test_lem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " array([0.12185658, 0.16966756, 0.20326518, 0.23018925, 0.2515358 ,\n",
       "        0.27062838, 0.28792218, 0.30358516, 0.31885922, 0.32964299]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words = Counter()\n",
    "\n",
    "for d in [train_lem[0]]:\n",
    "    for q in d:\n",
    "        for word in q:\n",
    "            count_words[word] += 1\n",
    "        \n",
    "freq, counts = np.unique(np.array(list(count_words.values())), return_counts=True) \n",
    "p = counts * freq \n",
    "p = p / p.sum()\n",
    "p = np.cumsum(p)\n",
    "freq[:10], p[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A', 'A-PRO', 'A-PRO=f', 'A-PRO=m', 'A-PRO=n', 'A-PRO=pl',\n",
       "        'A-PRO=sg', 'A=brev', 'A=comp', 'A=comp2', 'A=f', 'A=m', 'A=n',\n",
       "        'A=pl', 'A=sg', 'ADV', 'ADV-PRO', 'ADV-PRO=abbr', 'ADV-PRO=comp',\n",
       "        'ADV-PRO=distort', 'ADV=abbr', 'ADV=comp', 'ADV=comp2',\n",
       "        'ANUM=ciph', 'ANUM=f', 'ANUM=m', 'ANUM=n', 'ANUM=pl', 'ANUM=sg',\n",
       "        'CONJ', 'INIT=abbr', 'INTJ', 'INTJ=distort', 'NONLEX',\n",
       "        'NONLEX=abbr', 'NUM', 'NUM=acc', 'NUM=ciph', 'NUM=comp', 'NUM=dat',\n",
       "        'NUM=f', 'NUM=gen', 'NUM=ins', 'NUM=loc', 'NUM=m', 'NUM=n',\n",
       "        'NUM=nom', 'PARENTH', 'PART', 'PR', 'PRAEDIC', 'PRAEDIC-PRO',\n",
       "        'PRAEDIC=comp', 'S', 'S-PRO', 'S-PRO=acc', 'S-PRO=dat',\n",
       "        'S-PRO=gen', 'S-PRO=ins', 'S-PRO=loc', 'S-PRO=n=sg', 'S-PRO=pl',\n",
       "        'S=m', 'V'], dtype='<U32'), 64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = np.unique(np.hstack(train_lem[1]))\n",
    "tmp1 = np.unique(np.hstack(test_lem[1]))\n",
    "tmp = np.hstack([tmp, tmp1])\n",
    "tmp = np.unique(tmp)\n",
    "tmp, len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = tmp\n",
    "tags_to_ind = {}\n",
    "ind = 0\n",
    "for t in tags:\n",
    "    tags_to_ind[t] = ind\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сетки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Просто добавляем тег как фичу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_2 = KeyedVectors.load_word2vec_format(\"ft_native_300_ru_wiki_lenta_lower_case.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_n_tokens(emb):\n",
    "    n_tokens = 0\n",
    "    for word in count_words.keys():\n",
    "        if word in emb.vocab and count_words[word] >= 3:\n",
    "            n_tokens += 1\n",
    "    return n_tokens + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_features(emb, emb_size, ind_to_word, batch_x, batch_x_tags):\n",
    "    to_emb = np.zeros((len(batch_x), len(batch_x[0])+1, emb_size + len(tags)))\n",
    "    for i in range(len(batch_x)):\n",
    "        to_emb[i][0] = np.ones(emb_size + len(tags))\n",
    "        for j in range(len(batch_x[i])):\n",
    "            if batch_x[i][j] != pad_id:\n",
    "                to_emb[i][j+1][:emb_size] = emb[ind_to_word[batch_x[i][j]]]\n",
    "                if batch_x_tags[i][j] >= 0:\n",
    "                    to_emb[i][j+1][emb_size + batch_x_tags[i][j]] = 1\n",
    "    return to_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, emb, ind_to_word, emb_size=300, lstm_units=256):\n",
    "        super(self.__class__, self).__init__()\n",
    "        n_tokens = calculate_n_tokens(emb)\n",
    "        self.lstm = nn.LSTM(emb_size + len(tags), lstm_units, batch_first=True)\n",
    "        self.logits = nn.Linear(lstm_units, n_tokens) \n",
    "        self.emb = emb\n",
    "        self.emb_size = emb_size\n",
    "        self.ind_to_word = ind_to_word\n",
    "        \n",
    "    def forward(self, batch_x, batch_x_tags):\n",
    "        input_emb = transform_to_features(self.emb, self.emb_size, self.ind_to_word, batch_x, batch_x_tags)\n",
    "        input_emb = torch.tensor(input_emb, dtype=torch.float32)\n",
    "        lstm_out = self.lstm(input_emb)\n",
    "        logits = self.logits(lstm_out[0])\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = '#PAD#'\n",
    "pad_id = 0\n",
    "\n",
    "def construct_vocab(emb, count_words):\n",
    "    word_to_ind = dict()\n",
    "    word_to_ind['#PAD#'] = 0\n",
    "    ind_to_word = ['#PAD#', ]\n",
    "    \n",
    "    count = 1\n",
    "    for word in count_words.keys():\n",
    "        if count_words[word] >= 3 and word in emb.vocab:\n",
    "            ind_to_word.append(word)\n",
    "            word_to_ind[word] = count\n",
    "            count += 1\n",
    "    return ind_to_word, word_to_ind\n",
    "\n",
    "\n",
    "def as_matrix(sequences, tags, word_to_ind, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    max_len = max_len or max(map(len,sequences))\n",
    "    \n",
    "    matrix = np.zeros((2, len(sequences), max_len), dtype=int)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        for j, word in enumerate(seq[:max_len]):\n",
    "            if word in word_to_ind.keys():\n",
    "                matrix[0][i][j] = word_to_ind[word]\n",
    "                matrix[1][i][j] = tags_to_ind[tags[i][j]]\n",
    "            else:\n",
    "                matrix[0][i][j] = pad_id\n",
    "                matrix[1][i][j] = -1\n",
    "        for j in range(max_len, len(seq)):\n",
    "            matrix[0][i][j] = pad_id\n",
    "            matrix[1][i][j] = -1\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(network, batch):\n",
    "    \"\"\"\n",
    "    use scalar crossentropy loss (neg llh) loss \n",
    "    \"\"\"\n",
    "    batch_x = batch[0]\n",
    "    batch_tags = batch[1]\n",
    "    batch_x = np.array(batch_x)\n",
    "    batch_tags = np.array(batch_tags)\n",
    "\n",
    "    batch_x_inp = batch_x[:, :-1]\n",
    "    batch_x_next = batch_x[:, 1:]\n",
    "    batch_tags_inp = batch_tags[:, :-1]\n",
    "    batch_tags_next = batch_tags[:, 1:]\n",
    "    \n",
    "    logits_for_next = network.forward(batch_x_inp, batch_tags_inp)\n",
    "    logits_for_next = logits_for_next[:, 1:]\n",
    "    \n",
    "    answers = torch.argmax(logits_for_next, dim=-1).numpy()\n",
    "    logits_for_next = logits_for_next.contiguous()\n",
    "    logits_for_next = logits_for_next.view(-1, logits_for_next.shape[-1])\n",
    "    \n",
    "    accr = np.array([answers == batch_x_next]) * np.array([answers != pad_id])\n",
    "    accr = accr.sum()\n",
    "    to_div = np.sum(np.array([batch_x_next != pad_id]))\n",
    "    batch_x_next = torch.tensor(batch_x_next, dtype=torch.int64)\n",
    "    batch_x_next = batch_x_next.view(-1)\n",
    "    \n",
    "    loss = F.cross_entropy(logits_for_next, batch_x_next, ignore_index=pad_id, reduction='mean')\n",
    "    \n",
    "    \n",
    "    return loss, accr, to_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "def generate_batch(train, batch_size, word_to_ind, max_len=None):\n",
    "    random_x = np.random.randint(0, len(train[0]), size=batch_size)\n",
    "    batch_x = []\n",
    "    batch_tags = []\n",
    "    for x in random_x:\n",
    "        batch_x.append(train[0][x])\n",
    "        batch_tags.append(train[1][x])\n",
    "    return as_matrix(batch_x, batch_tags, word_to_ind, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "n_epochs = 20 \n",
    "n_batches_per_epoch = 400  \n",
    "n_validation_batches = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:03<00:00,  2.61it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, train loss: 7.415038217306137, val loss: 7.029473960399628\n",
      "\n",
      "Epoch: 0, train accr: 0.06012615392945126, val accr: 0.08210409128861676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:40<00:00,  2.90it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, train loss: 6.588179706335068, val loss: 6.555705967545509\n",
      "\n",
      "Epoch: 1, train accr: 0.10989722424536699, val accr: 0.10720432751413818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:43<00:00,  1.74it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, train loss: 6.104913908243179, val loss: 6.365627136826515\n",
      "\n",
      "Epoch: 2, train accr: 0.13640310414066315, val accr: 0.12206235872412184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:43<00:00,  1.97it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3, train loss: 5.751491576433182, val loss: 6.201145070791244\n",
      "\n",
      "Epoch: 3, train accr: 0.1518869828456105, val accr: 0.12976097595574154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:45<00:00,  2.75it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4, train loss: 5.463841874599456, val loss: 6.125228527188301\n",
      "\n",
      "Epoch: 4, train accr: 0.165665875974246, val accr: 0.13747347980869504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:42<00:00,  2.35it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5, train loss: 5.223688576221466, val loss: 6.060811606049538\n",
      "\n",
      "Epoch: 5, train accr: 0.18190424668650257, val accr: 0.1438562857244293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:45<00:00,  2.44it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6, train loss: 5.02456667304039, val loss: 6.020030668377876\n",
      "\n",
      "Epoch: 6, train accr: 0.1990015235607792, val accr: 0.1467916159954217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:43<00:00,  2.47it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7, train loss: 4.8251614201068875, val loss: 5.995430633425713\n",
      "\n",
      "Epoch: 7, train accr: 0.2121998000918497, val accr: 0.15825107793179632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:43<00:00,  2.48it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8, train loss: 4.649763660430908, val loss: 5.9933482021093365\n",
      "\n",
      "Epoch: 8, train accr: 0.22680231774693438, val accr: 0.1587067299244421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:47<00:00,  2.68it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9, train loss: 4.489338699579239, val loss: 6.045060223340988\n",
      "\n",
      "Epoch: 9, train accr: 0.24403225806451612, val accr: 0.15648024700021052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:42<00:00,  2.60it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10, train loss: 4.325403891801834, val loss: 6.019878289103508\n",
      "\n",
      "Epoch: 10, train accr: 0.26187012844439567, val accr: 0.16132177681473456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:47<00:00,  2.01it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11, train loss: 4.19681582570076, val loss: 6.081585231423378\n",
      "\n",
      "Epoch: 11, train accr: 0.27377579927155, val accr: 0.15985796653072704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:42<00:00,  2.76it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12, train loss: 4.03578318297863, val loss: 6.066061696410179\n",
      "\n",
      "Epoch: 12, train accr: 0.29419314742758323, val accr: 0.160538179768949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:41<00:00,  2.31it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13, train loss: 3.9093258064985275, val loss: 6.077114847302437\n",
      "\n",
      "Epoch: 13, train accr: 0.3083000203265804, val accr: 0.1633900956308436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:40<00:00,  2.30it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14, train loss: 3.779133513569832, val loss: 6.045979431271553\n",
      "\n",
      "Epoch: 14, train accr: 0.32664359861591696, val accr: 0.16685357818742552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:46<00:00,  2.33it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15, train loss: 3.6739465874433517, val loss: 6.1165186882019045\n",
      "\n",
      "Epoch: 15, train accr: 0.33969682230869, val accr: 0.16361121946030283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:47<00:00,  2.36it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16, train loss: 3.5566707360744476, val loss: 6.144429913163185\n",
      "\n",
      "Epoch: 16, train accr: 0.3544253050206465, val accr: 0.16442361894024804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:46<00:00,  2.56it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17, train loss: 3.459779422879219, val loss: 6.2179121434688565\n",
      "\n",
      "Epoch: 17, train accr: 0.3693340342080789, val accr: 0.16126997476871321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:42<00:00,  2.48it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18, train loss: 3.383422926068306, val loss: 6.212906065583229\n",
      "\n",
      "Epoch: 18, train accr: 0.38028302014056575, val accr: 0.16483516483516483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:51<00:00,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19, train loss: 3.2591949808597565, val loss: 6.271716690063476\n",
      "\n",
      "Epoch: 19, train accr: 0.3971612212104981, val accr: 0.15462953340953964\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "ind_to_word, word_to_ind = construct_vocab(emb_2, count_words)\n",
    "network = Net(emb_2, ind_to_word)\n",
    "opt = Adam(network.parameters())\n",
    "\n",
    "train_loss, val_loss, train_accr, val_accr = [], [], [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss_=0\n",
    "    train_accr_=0\n",
    "    to_div = 0\n",
    "    network.train(True)\n",
    "    for _ in tqdm(range(n_batches_per_epoch)):\n",
    "        \n",
    "        loss_t, accr_t, to_div_t = compute_loss(network, generate_batch(train_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        loss_t.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        train_loss_ += loss_t.item()\n",
    "        train_accr_ += accr_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    train_loss_ /= n_batches_per_epoch\n",
    "    #train_accr_ /= n_batches_per_epoch\n",
    "    train_accr_ /= to_div\n",
    "    \n",
    "    val_loss_=0\n",
    "    val_accr_=0\n",
    "    to_div = 0\n",
    "    network.train(False)\n",
    "    for _ in range(n_validation_batches):\n",
    "        loss_t, accr_t, to_div_t = compute_loss(network, generate_batch(test_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        val_loss_ += loss_t.item()\n",
    "        val_accr_ += accr_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    val_loss_ /= n_validation_batches\n",
    "    #val_accr_ /= n_validation_batches\n",
    "    val_accr_ /= to_div\n",
    "    \n",
    "    train_loss.append(train_loss_)\n",
    "    val_loss.append(val_loss_)\n",
    "    train_accr.append(train_accr_)\n",
    "    val_accr.append(val_accr_)\n",
    "    \n",
    "    print('\\nEpoch: {}, train loss: {}, val loss: {}'.format(epoch, train_loss_, val_loss_))\n",
    "    print('\\nEpoch: {}, train accr: {}, val accr: {}'.format(epoch, train_accr_, val_accr_))\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), 'add_pos_tagging_as_feature.pwf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accr(network, batch):\n",
    "    batch_x = batch[0]\n",
    "    batch_tag = batch[1]\n",
    "    \n",
    "    batch_x = np.array(batch_x)\n",
    "    batch_tag = np.array(batch_tag)\n",
    "    batch_x_inp = batch_x[:, :-1]\n",
    "    batch_x_next = batch_x[:, 1:]\n",
    "    batch_tag_inp = batch_tag[:, :-1]\n",
    "    batch_tag_next = batch_tag[:, 1:]\n",
    "    \n",
    "    logits_for_next = network.forward(batch_x_inp, batch_tag_inp)\n",
    "    logits_for_next = logits_for_next[:, 1:]\n",
    "    \n",
    "    answers = torch.argmax(logits_for_next, dim=-1).numpy()\n",
    "    \n",
    "    accr = np.array([answers == batch_x_next]) * np.array([answers != pad_id])\n",
    "    accr = accr[0]\n",
    "    accr = accr.sum(axis=0)\n",
    "    to_divide = np.array([batch_x_next != pad_id])[0].sum(axis=0)\n",
    "    \n",
    "    return accr, to_divide\n",
    "\n",
    "def get_batch(data, left, right, batch_size, word_to_ind, max_len=None):\n",
    "    slice_x = np.arange(left, right, 1)\n",
    "    batch_x = []\n",
    "    batch_tag = []\n",
    "    for x in slice_x:\n",
    "        batch_x.append(data[0][x])\n",
    "        batch_tag.append(data[1][x])\n",
    "    return as_matrix(batch_x, batch_tag, word_to_ind, max_len)\n",
    "\n",
    "def try_lengthes(data):\n",
    "    accr = np.zeros(np.max(list(map(len, data[0]))))\n",
    "    to_div = np.zeros(np.max(list(map(len, data[0]))))\n",
    "    \n",
    "    for _ in tqdm_notebook(range(0, len(data[0])-batch_size, batch_size)):\n",
    "        accr_t, div_t = compute_accr(network, get_batch(data, _, _+batch_size, batch_size, word_to_ind))\n",
    "        accr[:len(accr_t)] += accr_t\n",
    "        to_div[:len(div_t)] += div_t\n",
    "    eps = 1\n",
    "    return accr / (to_div + eps), accr.sum() / to_div.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_pad(data):\n",
    "    to_pad = 0\n",
    "    all_ = 0\n",
    "    for x in data:\n",
    "        for word in x:\n",
    "            all_ += 1\n",
    "            if word not in word_to_ind.keys():\n",
    "                to_pad += 1\n",
    "    return to_pad / all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6564a008527b4987ab9899209c1ec92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=802), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.22534229, 0.3419334 , 0.46927353, 0.51727253, 0.55219961,\n",
       "        0.5572743 , 0.57848837, 0.58447489, 0.56936226, 0.54239257]),\n",
       " 0.4007140359841863)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "on_train, all_accr = try_lengthes(train_lem)\n",
    "on_train[:10], all_accr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dad748fd7a7480d939b4e603f541a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=330), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.13774834, 0.14425538, 0.16985902, 0.1910342 , 0.18946509,\n",
       "        0.19265442, 0.19807281, 0.18886861, 0.16057234, 0.11239193]),\n",
       " 0.1608981155306269)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_test, all_accr = try_lengthes(test_lem)\n",
    "on_test[:10], all_accr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* попробуем учить предсказание следующего тега"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWithTags(nn.Module):\n",
    "    def __init__(self, emb, ind_to_word, emb_size=300, lstm_units=256):\n",
    "        super(self.__class__, self).__init__()\n",
    "        n_tokens = calculate_n_tokens(emb)\n",
    "        self.lstm = nn.LSTM(emb_size + len(tags), lstm_units, batch_first=True)\n",
    "        self.logits = nn.Linear(lstm_units, n_tokens) \n",
    "        self.logits_tags = nn.Linear(lstm_units, len(tags))\n",
    "        self.emb = emb\n",
    "        self.emb_size = emb_size\n",
    "        self.ind_to_word = ind_to_word\n",
    "        \n",
    "    def forward(self, batch_x, batch_x_tags):\n",
    "        input_emb = transform_to_features(self.emb, self.emb_size, self.ind_to_word, batch_x, batch_x_tags)\n",
    "        input_emb = torch.tensor(input_emb, dtype=torch.float32)\n",
    "        lstm_out = self.lstm(input_emb)\n",
    "        logits = self.logits(lstm_out[0])\n",
    "        logits_tags = self.logits_tags(lstm_out[0])\n",
    "        return logits, logits_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(network, batch):\n",
    "    \"\"\"\n",
    "    use scalar crossentropy loss (neg llh) loss \n",
    "    \"\"\"\n",
    "    batch_x = batch[0]\n",
    "    batch_tags = batch[1]\n",
    "    batch_x = np.array(batch_x)\n",
    "    batch_tags = np.array(batch_tags)\n",
    "\n",
    "    batch_x_inp = batch_x[:, :-1]\n",
    "    batch_x_next = batch_x[:, 1:]\n",
    "    batch_tags_inp = batch_tags[:, :-1]\n",
    "    batch_tags_next = batch_tags[:, 1:]\n",
    "    \n",
    "    logits_for_next, logits_tags_for_next = network.forward(batch_x_inp, batch_tags_inp)\n",
    "    logits_for_next = logits_for_next[:, 1:]\n",
    "    logits_tags_for_next = logits_tags_for_next[:, 1:]\n",
    "    \n",
    "    answers = torch.argmax(logits_for_next, dim=-1).numpy()\n",
    "    tags = torch.argmax(logits_tags_for_next, dim=-1).numpy()\n",
    "    logits_for_next = logits_for_next.contiguous()\n",
    "    logits_for_next = logits_for_next.view(-1, logits_for_next.shape[-1])\n",
    "    logits_tags_for_next = logits_tags_for_next.contiguous()\n",
    "    logits_tags_for_next = logits_tags_for_next.view(-1, logits_tags_for_next.shape[-1])\n",
    "    \n",
    "    accr = np.array([answers == batch_x_next]) * np.array([answers != pad_id])\n",
    "    accr = accr.sum()\n",
    "    accr_tags = np.array([tags == batch_tags_next]) * np.array([batch_x_next != pad_id])\n",
    "    accr_tags = accr_tags.sum()\n",
    "    to_div = np.sum(np.array([batch_x_next != pad_id]))\n",
    "    \n",
    "    batch_x_next = torch.tensor(batch_x_next, dtype=torch.int64)\n",
    "    batch_x_next = batch_x_next.view(-1)\n",
    "    batch_tags_next = torch.tensor(batch_tags_next, dtype=torch.int64)\n",
    "    batch_tags_next = batch_tags_next.view(-1)\n",
    "    \n",
    "    loss = F.cross_entropy(logits_for_next, batch_x_next, ignore_index=pad_id, reduction='mean')\n",
    "    loss += F.cross_entropy(logits_tags_for_next, batch_tags_next, ignore_index=-1, reduction='mean')\n",
    "    \n",
    "    return loss, accr, accr_tags, to_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:43<00:00,  2.49it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, train loss: 8.267957304716111, val loss: 7.728692108392716\n",
      "\n",
      "Epoch: 0, train accr: 0.05421031152224187, val accr: 0.07534610345926425\n",
      "\n",
      "Epoch: 0, train accr tags: 0.3698000272071827, val accr tags: 0.4069680982898417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:42<00:00,  2.43it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, train loss: 7.374649313688278, val loss: 7.271440061926842\n",
      "\n",
      "Epoch: 1, train accr: 0.10069555484489927, val accr: 0.09989834904833678\n",
      "\n",
      "Epoch: 1, train accr tags: 0.43771985929005436, val accr tags: 0.43352378281748394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:50<00:00,  2.52it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, train loss: 6.878707815408706, val loss: 7.069121909141541\n",
      "\n",
      "Epoch: 2, train accr: 0.12169775717058443, val accr: 0.11507711900382057\n",
      "\n",
      "Epoch: 2, train accr tags: 0.4559790813025663, val accr tags: 0.45670015565303523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:47<00:00,  1.97it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3, train loss: 6.527763129472732, val loss: 6.842003047466278\n",
      "\n",
      "Epoch: 3, train accr: 0.13974178874841126, val accr: 0.12707162921348314\n",
      "\n",
      "Epoch: 3, train accr tags: 0.4575824469864205, val accr tags: 0.44476825842696627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:46<00:00,  2.64it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4, train loss: 6.257463295459747, val loss: 6.79649071097374\n",
      "\n",
      "Epoch: 4, train accr: 0.15493754038337282, val accr: 0.13386904344164502\n",
      "\n",
      "Epoch: 4, train accr tags: 0.46859519707085934, val accr tags: 0.4391185346340094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:59<00:00,  2.46it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5, train loss: 6.005881768465042, val loss: 6.6623375654220585\n",
      "\n",
      "Epoch: 5, train accr: 0.16684726661971067, val accr: 0.14521770164168452\n",
      "\n",
      "Epoch: 5, train accr tags: 0.47251720214552745, val accr tags: 0.4359386152748037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:42<00:00,  2.25it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6, train loss: 5.798693032264709, val loss: 6.66399749815464\n",
      "\n",
      "Epoch: 6, train accr: 0.18230402181322428, val accr: 0.14916307648845256\n",
      "\n",
      "Epoch: 6, train accr tags: 0.47426039536468984, val accr tags: 0.44416978600183626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:43<00:00,  2.64it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7, train loss: 5.588264954090119, val loss: 6.62012488245964\n",
      "\n",
      "Epoch: 7, train accr: 0.1962257090160648, val accr: 0.14937150837988827\n",
      "\n",
      "Epoch: 7, train accr tags: 0.47885648606024966, val accr tags: 0.4510474860335196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:40<00:00,  2.96it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8, train loss: 5.41773368358612, val loss: 6.633986100554466\n",
      "\n",
      "Epoch: 8, train accr: 0.21007303014349546, val accr: 0.14975620249533916\n",
      "\n",
      "Epoch: 8, train accr tags: 0.4800280781328042, val accr tags: 0.46522300301161623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:41<00:00,  1.86it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9, train loss: 5.211251986026764, val loss: 6.579390147328377\n",
      "\n",
      "Epoch: 9, train accr: 0.22919975236198217, val accr: 0.1606601901180403\n",
      "\n",
      "Epoch: 9, train accr tags: 0.4898253075287341, val accr tags: 0.4685051707928549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:45<00:00,  2.21it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10, train loss: 5.050846446752548, val loss: 6.661893221735954\n",
      "\n",
      "Epoch: 10, train accr: 0.2410517160634241, val accr: 0.15630931458699474\n",
      "\n",
      "Epoch: 10, train accr tags: 0.4902923663611427, val accr tags: 0.45669595782073813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:43<00:00,  2.51it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11, train loss: 4.901814500689507, val loss: 6.61885007917881\n",
      "\n",
      "Epoch: 11, train accr: 0.2562428749796428, val accr: 0.1640438386960798\n",
      "\n",
      "Epoch: 11, train accr tags: 0.4925492644264698, val accr tags: 0.45001405086412816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:46<00:00,  2.24it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12, train loss: 4.727243905067444, val loss: 6.598089098930359\n",
      "\n",
      "Epoch: 12, train accr: 0.27415812098263015, val accr: 0.1654510556621881\n",
      "\n",
      "Epoch: 12, train accr tags: 0.4962605613874328, val accr tags: 0.4618740184958995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:42<00:00,  2.50it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13, train loss: 4.613934078216553, val loss: 6.704738259315491\n",
      "\n",
      "Epoch: 13, train accr: 0.2911463712327481, val accr: 0.15886569681636095\n",
      "\n",
      "Epoch: 13, train accr tags: 0.4976326837184973, val accr tags: 0.4627521259399817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:44<00:00,  2.28it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14, train loss: 4.453952410817147, val loss: 6.644101104140281\n",
      "\n",
      "Epoch: 14, train accr: 0.3092866756393001, val accr: 0.16365486508298538\n",
      "\n",
      "Epoch: 14, train accr tags: 0.50185733512786, val accr tags: 0.4715604056282677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:47<00:00,  2.26it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15, train loss: 4.355333862304687, val loss: 6.73932549059391\n",
      "\n",
      "Epoch: 15, train accr: 0.31899863842866577, val accr: 0.1647569991940853\n",
      "\n",
      "Epoch: 15, train accr tags: 0.50301298211084, val accr tags: 0.45022600651739725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:49<00:00,  2.25it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16, train loss: 4.234209511876106, val loss: 6.710313439369202\n",
      "\n",
      "Epoch: 16, train accr: 0.33668321588725175, val accr: 0.16350416740556836\n",
      "\n",
      "Epoch: 16, train accr tags: 0.5064995729233397, val accr tags: 0.4584855470828161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:49<00:00,  2.55it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17, train loss: 4.119367979168892, val loss: 6.804924938082695\n",
      "\n",
      "Epoch: 17, train accr: 0.34934791981030394, val accr: 0.16087094387485468\n",
      "\n",
      "Epoch: 17, train accr tags: 0.5083800388014659, val accr tags: 0.44833174787725044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:41<00:00,  2.44it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18, train loss: 4.033529533743859, val loss: 6.821166551113128\n",
      "\n",
      "Epoch: 18, train accr: 0.365685019206146, val accr: 0.16335493160547157\n",
      "\n",
      "Epoch: 18, train accr tags: 0.5113282566210661, val accr tags: 0.4712023038156947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:55<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19, train loss: 3.9156561106443406, val loss: 6.831090602278709\n",
      "\n",
      "Epoch: 19, train accr: 0.380852176010937, val accr: 0.16100197851893724\n",
      "\n",
      "Epoch: 19, train accr tags: 0.5127263466873969, val accr tags: 0.4583451102317694\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "ind_to_word, word_to_ind = construct_vocab(emb_2, count_words)\n",
    "network = NetWithTags(emb_2, ind_to_word)\n",
    "opt = Adam(network.parameters())\n",
    "\n",
    "train_loss, val_loss, train_accr, val_accr, train_tags_accr, val_tags_accr = [], [], [], [], [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss_=0\n",
    "    train_accr_=0\n",
    "    train_accr_tags_=0\n",
    "    to_div = 0\n",
    "    network.train(True)\n",
    "    for _ in tqdm(range(n_batches_per_epoch)):\n",
    "        \n",
    "        loss_t, accr_t, accr_tags_t, to_div_t = compute_loss(network, generate_batch(train_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        loss_t.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        train_loss_ += loss_t.item()\n",
    "        train_accr_ += accr_t.item()\n",
    "        train_accr_tags_ += accr_tags_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    train_loss_ /= n_batches_per_epoch\n",
    "    #train_accr_ /= n_batches_per_epoch\n",
    "    train_accr_ /= to_div\n",
    "    train_accr_tags_ /= to_div\n",
    "    \n",
    "    val_loss_=0\n",
    "    val_accr_=0\n",
    "    val_accr_tags_=0\n",
    "    to_div = 0\n",
    "    network.train(False)\n",
    "    for _ in range(n_validation_batches):\n",
    "        loss_t, accr_t, accr_tags_t, to_div_t = compute_loss(network, generate_batch(test_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        val_loss_ += loss_t.item()\n",
    "        val_accr_ += accr_t.item()\n",
    "        val_accr_tags_ += accr_tags_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    val_loss_ /= n_validation_batches\n",
    "    #val_accr_ /= n_validation_batches\n",
    "    val_accr_ /= to_div\n",
    "    val_accr_tags_ /= to_div\n",
    "    \n",
    "    train_loss.append(train_loss_)\n",
    "    val_loss.append(val_loss_)\n",
    "    train_accr.append(train_accr_)\n",
    "    val_accr.append(val_accr_)\n",
    "    train_tags_accr.append(train_accr_tags_)\n",
    "    val_tags_accr.append(val_accr_tags_)\n",
    "    \n",
    "    print('\\nEpoch: {}, train loss: {}, val loss: {}'.format(epoch, train_loss_, val_loss_))\n",
    "    print('\\nEpoch: {}, train accr: {}, val accr: {}'.format(epoch, train_accr_, val_accr_))\n",
    "    print('\\nEpoch: {}, train accr tags: {}, val accr tags: {}'.format(epoch, train_accr_tags_, val_accr_tags_))\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), 'add_pos_tagging_as_feature_and_in_loss.pwf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accr(network, batch):\n",
    "    batch_x = batch[0]\n",
    "    batch_tag = batch[1]\n",
    "    \n",
    "    batch_x = np.array(batch_x)\n",
    "    batch_tag = np.array(batch_tag)\n",
    "    batch_x_inp = batch_x[:, :-1]\n",
    "    batch_x_next = batch_x[:, 1:]\n",
    "    batch_tag_inp = batch_tag[:, :-1]\n",
    "    batch_tag_next = batch_tag[:, 1:]\n",
    "    \n",
    "    logits_for_next, logits_tags_for_next = network.forward(batch_x_inp, batch_tag_inp)\n",
    "    logits_for_next = logits_for_next[:, 1:]\n",
    "    logits_tags_for_next = logits_tags_for_next[:, 1:]\n",
    "    \n",
    "    answers = torch.argmax(logits_for_next, dim=-1).numpy()\n",
    "    tags = torch.argmax(logits_tags_for_next, dim=-1).numpy()\n",
    "    \n",
    "    accr = np.array([answers == batch_x_next]) * np.array([answers != pad_id])\n",
    "    accr = accr[0]\n",
    "    accr = accr.sum(axis=0)\n",
    "    accr_tags = np.array([tags == batch_tag_next]) * np.array([batch_x_next != pad_id])\n",
    "    accr_tags = accr_tags[0]\n",
    "    accr_tags = accr_tags.sum(axis=0)\n",
    "    to_divide = np.array([batch_x_next != pad_id])[0].sum(axis=0)\n",
    "    \n",
    "    return accr, accr_tags, to_divide\n",
    "\n",
    "def get_batch(data, left, right, batch_size, word_to_ind, max_len=None):\n",
    "    slice_x = np.arange(left, right, 1)\n",
    "    batch_x = []\n",
    "    batch_tag = []\n",
    "    for x in slice_x:\n",
    "        batch_x.append(data[0][x])\n",
    "        batch_tag.append(data[1][x])\n",
    "    return as_matrix(batch_x, batch_tag, word_to_ind, max_len)\n",
    "\n",
    "def try_lengthes(data):\n",
    "    accr = np.zeros(np.max(list(map(len, data[0]))))\n",
    "    accr_tags = np.zeros(np.max(list(map(len, data[0]))))\n",
    "    to_div = np.zeros(np.max(list(map(len, data[0]))))\n",
    "    \n",
    "    for _ in tqdm_notebook(range(0, len(data[0])-batch_size, batch_size)):\n",
    "        accr_t, accr_tags_t, div_t = compute_accr(network, get_batch(data, _, _+batch_size, batch_size, word_to_ind))\n",
    "        accr[:len(accr_t)] += accr_t\n",
    "        to_div[:len(div_t)] += div_t\n",
    "        accr_tags[:len(accr_tags_t)] += accr_tags_t\n",
    "    eps = 1\n",
    "    return accr / (to_div + eps), accr_tags / (to_div + eps), accr.sum() / to_div.sum(), accr_tags.sum() / to_div.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab0cffa8af64c3083e42a9822fe250b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=802), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.219969  , 0.32748882, 0.45278524, 0.49261267, 0.53258372,\n",
       "        0.52887052, 0.55344365, 0.54452055, 0.53320184, 0.49361208]),\n",
       " array([0.60958409, 0.51012003, 0.48772832, 0.4594494 , 0.42769206,\n",
       "        0.40512068, 0.40317531, 0.40905632, 0.40368179, 0.40998839]),\n",
       " 0.384947422209074,\n",
       " 0.5055805072210419)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "on_train, on_train_tags, all_accr, all_accr_tags = try_lengthes(train_lem)\n",
    "on_train[:10], on_train_tags[:10], all_accr, all_accr_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b213b7e2492a4f909a320d6b9e569cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=330), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.14      , 0.14794459, 0.17433155, 0.18912658, 0.19334422,\n",
       "        0.20400668, 0.20396146, 0.1979927 , 0.16216216, 0.11239193]),\n",
       " array([0.58516556, 0.45859057, 0.41915411, 0.39801063, 0.36504696,\n",
       "        0.35358932, 0.32601713, 0.34032847, 0.3608903 , 0.32564841]),\n",
       " 0.16418140155272068,\n",
       " 0.45334997776941754)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_test, on_test_tags, all_accr, all_accr_tags = try_lengthes(test_lem)\n",
    "on_test[:10], on_test_tags[:10], all_accr, all_accr_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* посмотрим насколько знание тэга может улучшить биграммное предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b3b531528a4adda44a30bca10461da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4ebe4850244c63a200ba3a76b4cc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cnt = dict()\n",
    "for i, line in tqdm_notebook(enumerate(train_lem[0])):\n",
    "    prefix = \"\"\n",
    "    for j, word in enumerate(line):\n",
    "        if prefix not in cnt.keys():\n",
    "            cnt[prefix] = Counter()\n",
    "        cnt[prefix][word] += 1\n",
    "        prefix = word\n",
    "\n",
    "accr = np.zeros(np.max(list(map(len, test_lem[0]))))\n",
    "to_div = np.zeros_like(accr)\n",
    "for i, line in tqdm_notebook(enumerate(test_lem[0])):\n",
    "    prefix = \"\"\n",
    "    for j, word in enumerate(line):\n",
    "        to_div[j] += 1\n",
    "        if prefix in cnt.keys() and cnt[prefix].most_common(1)[0][0] == word:\n",
    "            accr[j] += 1\n",
    "        prefix = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.91422634, 11.6593975 , 10.16124125, 12.48063911, 12.96511628,\n",
       "       12.91005291, 14.01091013, 14.58625526, 12.5399361 , 12.82051282,\n",
       "        8.27250608,  7.239819  ,  6.81818182,  4.87804878,  3.33333333,\n",
       "        0.        ,  3.03030303,  3.44827586,  4.34782609,  5.55555556,\n",
       "        6.66666667,  7.14285714,  7.69230769,  0.        ,  8.33333333,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , 12.5       ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , 25.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , 33.33333333,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accr / to_div * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75610ace71354be1aaa58c1a59d99229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006c3190a1af4c62a1a18abef8cf3979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cnt = dict()\n",
    "for i, line in tqdm_notebook(enumerate(train_lem[0])):\n",
    "    prefix = \"\"\n",
    "    prefix_tag = \"\"\n",
    "    for j, word in enumerate(line):\n",
    "        if prefix not in cnt.keys():\n",
    "            cnt[prefix] = dict()\n",
    "        if prefix_tag not in cnt[prefix].keys():\n",
    "            cnt[prefix][prefix_tag] = Counter()\n",
    "        cnt[prefix][prefix_tag][word] += 1\n",
    "        prefix = word\n",
    "        prefix_tag = train_lem[1][i][j]\n",
    "\n",
    "accr = np.zeros(np.max(list(map(len, test_lem[0]))))\n",
    "to_div = np.zeros_like(accr)\n",
    "for i, line in tqdm_notebook(enumerate(test_lem[0])):\n",
    "    prefix = \"\"\n",
    "    prefix_tag = \"\"\n",
    "    for j, word in enumerate(line):\n",
    "        to_div[j] += 1\n",
    "        if prefix in cnt.keys() and prefix_tag in cnt[prefix].keys() and cnt[prefix][prefix_tag].most_common(1)[0][0] == word:\n",
    "            accr[j] += 1\n",
    "        prefix = word\n",
    "        prefix_tag = test_lem[1][i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.91422634, 12.13611928, 10.31335564, 12.71704573, 13.46511628,\n",
       "       13.22751323, 14.38415159, 14.53950444, 12.69968051, 13.09041835,\n",
       "        8.27250608,  7.69230769,  6.81818182,  3.65853659,  3.33333333,\n",
       "        0.        ,  3.03030303,  3.44827586,  4.34782609,  5.55555556,\n",
       "        6.66666667,  7.14285714,  7.69230769,  0.        ,  8.33333333,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , 25.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , 50.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , 33.33333333,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accr / to_div * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* попробуем учить промежуточное представление тег"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWithInnerTags(nn.Module):\n",
    "    def __init__(self, emb, ind_to_word, emb_size=300, lstm_units=256):\n",
    "        super(self.__class__, self).__init__()\n",
    "        n_tokens = calculate_n_tokens(emb)\n",
    "        self.lstm = nn.LSTM(emb_size + len(tags), lstm_units, batch_first=True)\n",
    "        self.logits_tags = nn.Linear(lstm_units, len(tags))\n",
    "        self.logits = nn.Linear(lstm_units + len(tags), n_tokens) \n",
    "        self.emb = emb\n",
    "        self.emb_size = emb_size\n",
    "        self.ind_to_word = ind_to_word\n",
    "        \n",
    "    def forward(self, batch_x, batch_x_tags):\n",
    "        input_emb = transform_to_features(self.emb, self.emb_size, self.ind_to_word, batch_x, batch_x_tags)\n",
    "        input_emb = torch.tensor(input_emb, dtype=torch.float32)\n",
    "        lstm_out = self.lstm(input_emb)\n",
    "        logits_tags = self.logits_tags(lstm_out[0])\n",
    "        #print(lstm_out[0].shape)\n",
    "        #print(logits_tags.shape)\n",
    "        inner = torch.cat([lstm_out[0], logits_tags], dim=2)\n",
    "        #print(inner.shape)\n",
    "        logits = self.logits(inner)\n",
    "        return logits, logits_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:03<00:00,  2.36it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, train loss: 8.303791218996048, val loss: 7.757710286974907\n",
      "\n",
      "Epoch: 0, train accr: 0.05601673662612147, val accr: 0.07817403708987161\n",
      "\n",
      "Epoch: 0, train accr tags: 0.36281464991215956, val accr tags: 0.4117689015691869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:55<00:00,  2.39it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, train loss: 7.297870186567306, val loss: 7.279327535629273\n",
      "\n",
      "Epoch: 1, train accr: 0.10737599240008143, val accr: 0.10968498897816967\n",
      "\n",
      "Epoch: 1, train accr tags: 0.44399810002035695, val accr tags: 0.43809997866742517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:55<00:00,  2.11it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, train loss: 6.776656460762024, val loss: 7.008813089132309\n",
      "\n",
      "Epoch: 2, train accr: 0.1310105840004298, val accr: 0.12266134118141686\n",
      "\n",
      "Epoch: 2, train accr tags: 0.4608472572932896, val accr tags: 0.4344124448181627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:50<00:00,  2.55it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3, train loss: 6.451160465478897, val loss: 6.857466557621956\n",
      "\n",
      "Epoch: 3, train accr: 0.14897292628282993, val accr: 0.13246927532137306\n",
      "\n",
      "Epoch: 3, train accr tags: 0.464733986557616, val accr tags: 0.45197061731883037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:51<00:00,  2.24it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4, train loss: 6.15686475276947, val loss: 6.807031381130218\n",
      "\n",
      "Epoch: 4, train accr: 0.164189225844952, val accr: 0.1385187263290784\n",
      "\n",
      "Epoch: 4, train accr tags: 0.47159984809851896, val accr tags: 0.43754383503997757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:04<00:00,  2.66it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5, train loss: 5.875315719842911, val loss: 6.746081846952438\n",
      "\n",
      "Epoch: 5, train accr: 0.1795619065525994, val accr: 0.14516241461034435\n",
      "\n",
      "Epoch: 5, train accr tags: 0.4771350676211069, val accr tags: 0.4516589990241182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:58<00:00,  1.33it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6, train loss: 5.629111404418945, val loss: 6.798665112257003\n",
      "\n",
      "Epoch: 6, train accr: 0.1997396998413796, val accr: 0.1504864711313117\n",
      "\n",
      "Epoch: 6, train accr tags: 0.48249074714279905, val accr tags: 0.45160144876074143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:54<00:00,  2.58it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7, train loss: 5.424141116142273, val loss: 6.70615745484829\n",
      "\n",
      "Epoch: 7, train accr: 0.21504924170487533, val accr: 0.1550010499055085\n",
      "\n",
      "Epoch: 7, train accr tags: 0.4830570552646572, val accr tags: 0.46052355288024077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:56<00:00,  1.89it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8, train loss: 5.191770613193512, val loss: 6.7624166160821915\n",
      "\n",
      "Epoch: 8, train accr: 0.23734861591695502, val accr: 0.15754123149418012\n",
      "\n",
      "Epoch: 8, train accr tags: 0.4867133434256055, val accr tags: 0.43984949185919753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:53<00:00,  2.06it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9, train loss: 5.021691401004791, val loss: 6.796793347597122\n",
      "\n",
      "Epoch: 9, train accr: 0.2539049384208335, val accr: 0.15474292193756423\n",
      "\n",
      "Epoch: 9, train accr tags: 0.4916260391904052, val accr tags: 0.4625987739626519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:59<00:00,  2.26it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10, train loss: 4.843171019554138, val loss: 6.7978469043970104\n",
      "\n",
      "Epoch: 10, train accr: 0.2731442869057548, val accr: 0.15801267462623858\n",
      "\n",
      "Epoch: 10, train accr tags: 0.4922247033818505, val accr tags: 0.46185357655544274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:58<00:00,  2.43it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11, train loss: 4.681850023269654, val loss: 6.847008913755417\n",
      "\n",
      "Epoch: 11, train accr: 0.2887386538098958, val accr: 0.15620182200420463\n",
      "\n",
      "Epoch: 11, train accr tags: 0.49781829935087674, val accr tags: 0.45749824807288014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:55<00:00,  2.29it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12, train loss: 4.507625972032547, val loss: 6.858459803462028\n",
      "\n",
      "Epoch: 12, train accr: 0.31058614133732454, val accr: 0.15811226111837226\n",
      "\n",
      "Epoch: 12, train accr tags: 0.5003303534107304, val accr tags: 0.47497262354728176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:53<00:00,  2.60it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13, train loss: 4.37376730620861, val loss: 6.971800044178963\n",
      "\n",
      "Epoch: 13, train accr: 0.32655122266508674, val accr: 0.15913213587053174\n",
      "\n",
      "Epoch: 13, train accr tags: 0.5030297317677475, val accr tags: 0.4683620842966388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:56<00:00,  2.43it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14, train loss: 4.2266193014383315, val loss: 6.9484130322933195\n",
      "\n",
      "Epoch: 14, train accr: 0.3444690803882865, val accr: 0.15395299145299146\n",
      "\n",
      "Epoch: 14, train accr tags: 0.5085174269258849, val accr tags: 0.44985754985754983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:57<00:00,  2.14it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15, train loss: 4.115387309193611, val loss: 7.036811563372612\n",
      "\n",
      "Epoch: 15, train accr: 0.361919168931311, val accr: 0.16159775753328662\n",
      "\n",
      "Epoch: 15, train accr tags: 0.5126173041138435, val accr tags: 0.4536790469516468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:56<00:00,  1.92it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16, train loss: 3.9755023175477984, val loss: 7.075371396541596\n",
      "\n",
      "Epoch: 16, train accr: 0.3782862641842313, val accr: 0.15427919903085585\n",
      "\n",
      "Epoch: 16, train accr tags: 0.5138267017736137, val accr tags: 0.4617686880923537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:56<00:00,  2.29it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17, train loss: 3.865159631371498, val loss: 7.12977782189846\n",
      "\n",
      "Epoch: 17, train accr: 0.39209714154795755, val accr: 0.15765955949616495\n",
      "\n",
      "Epoch: 17, train accr tags: 0.5127963234996833, val accr tags: 0.4556681443951868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [02:57<00:00,  2.54it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18, train loss: 3.735274168848991, val loss: 7.143848976492881\n",
      "\n",
      "Epoch: 18, train accr: 0.40771895101434935, val accr: 0.16508168739331872\n",
      "\n",
      "Epoch: 18, train accr tags: 0.5195715260039852, val accr tags: 0.46459051799212736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:30<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19, train loss: 3.6728498983383178, val loss: 7.258537444472313\n",
      "\n",
      "Epoch: 19, train accr: 0.42210088893072795, val accr: 0.15643330672312658\n",
      "\n",
      "Epoch: 19, train accr tags: 0.523487405693998, val accr tags: 0.463989448474541\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "ind_to_word, word_to_ind = construct_vocab(emb_2, count_words)\n",
    "network = NetWithInnerTags(emb_2, ind_to_word)\n",
    "opt = Adam(network.parameters())\n",
    "\n",
    "train_loss, val_loss, train_accr, val_accr, train_tags_accr, val_tags_accr = [], [], [], [], [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss_=0\n",
    "    train_accr_=0\n",
    "    train_accr_tags_=0\n",
    "    to_div = 0\n",
    "    network.train(True)\n",
    "    for _ in tqdm(range(n_batches_per_epoch)):\n",
    "        \n",
    "        loss_t, accr_t, accr_tags_t, to_div_t = compute_loss(network, generate_batch(train_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        loss_t.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        train_loss_ += loss_t.item()\n",
    "        train_accr_ += accr_t.item()\n",
    "        train_accr_tags_ += accr_tags_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    train_loss_ /= n_batches_per_epoch\n",
    "    #train_accr_ /= n_batches_per_epoch\n",
    "    train_accr_ /= to_div\n",
    "    train_accr_tags_ /= to_div\n",
    "    \n",
    "    val_loss_=0\n",
    "    val_accr_=0\n",
    "    val_accr_tags_=0\n",
    "    to_div = 0\n",
    "    network.train(False)\n",
    "    for _ in range(n_validation_batches):\n",
    "        loss_t, accr_t, accr_tags_t, to_div_t = compute_loss(network, generate_batch(test_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        val_loss_ += loss_t.item()\n",
    "        val_accr_ += accr_t.item()\n",
    "        val_accr_tags_ += accr_tags_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    val_loss_ /= n_validation_batches\n",
    "    #val_accr_ /= n_validation_batches\n",
    "    val_accr_ /= to_div\n",
    "    val_accr_tags_ /= to_div\n",
    "    \n",
    "    train_loss.append(train_loss_)\n",
    "    val_loss.append(val_loss_)\n",
    "    train_accr.append(train_accr_)\n",
    "    val_accr.append(val_accr_)\n",
    "    train_tags_accr.append(train_accr_tags_)\n",
    "    val_tags_accr.append(val_accr_tags_)\n",
    "    \n",
    "    print('\\nEpoch: {}, train loss: {}, val loss: {}'.format(epoch, train_loss_, val_loss_))\n",
    "    print('\\nEpoch: {}, train accr: {}, val accr: {}'.format(epoch, train_accr_, val_accr_))\n",
    "    print('\\nEpoch: {}, train accr tags: {}, val accr tags: {}'.format(epoch, train_accr_tags_, val_accr_tags_))\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), 'add_pos_tagging_inner_layer.pwf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcfcaddc1fc4fcbb2f76a0d6bedfbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=802), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.22645311, 0.3594081 , 0.50398971, 0.55208333, 0.59709455,\n",
       "        0.60381384, 0.62298748, 0.62519026, 0.60157791, 0.6155633 ]),\n",
       " array([0.61431155, 0.53768534, 0.51703664, 0.49819303, 0.4562541 ,\n",
       "        0.43232431, 0.42620751, 0.42656012, 0.41485865, 0.42508711]),\n",
       " 0.4249589866336767,\n",
       " 0.528104241185488)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_train, on_train_tags, all_accr, all_accr_tags = try_lengthes(train_lem)\n",
    "on_train[:10], on_train_tags[:10], all_accr, all_accr_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c89b3709794f22bcadd9e9eecb504b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=330), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.13437086, 0.14207198, 0.1718036 , 0.18258618, 0.18599428,\n",
       "        0.20033389, 0.17665953, 0.17244526, 0.14785374, 0.09221902]),\n",
       " array([0.58384106, 0.48004819, 0.4305299 , 0.41122769, 0.38321764,\n",
       "        0.36093489, 0.32762313, 0.35766423, 0.34022258, 0.32276657]),\n",
       " 0.15766613085262834,\n",
       " 0.46352474434830193)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_test, on_test_tags, all_accr, all_accr_tags = try_lengthes(test_lem)\n",
    "on_test[:10], on_test_tags[:10], all_accr, all_accr_tags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
