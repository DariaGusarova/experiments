{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_queries_with_lemmatization(path):\n",
    "    f = open(path)\n",
    "    queries = []\n",
    "    tags = []\n",
    "    mystem = Mystem()\n",
    "    tokenizer = WordPunctTokenizer()\n",
    "    \n",
    "    for line in f:\n",
    "        tmp = []\n",
    "        tmp_ = []\n",
    "        text = tokenizer.tokenize(line.lower())\n",
    "        text_tagged = nltk.pos_tag(text, lang='rus')\n",
    "        \n",
    "        for i, q in enumerate(text):\n",
    "            if not np.all(np.any(np.array(list(q)).reshape(-1, 1) == np.array(list(punctuation)).reshape(1, -1), axis=1)):\n",
    "                q_ = mystem.lemmatize(q)\n",
    "                tmp.append(\"\".join(q_).split()[0])\n",
    "                tmp_.append(text_tagged[i][1])\n",
    "        queries.append(tmp)\n",
    "        tags.append(tmp_)\n",
    "    f.close()\n",
    "    return (queries, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['сибирский', 'сеть', 'личный', 'кабинет', 'бердск'],\n",
       "  ['1', 'сантим', 'алжир', '1964'],\n",
       "  ['река', 'колыма', 'на', 'карта', 'россия'],\n",
       "  ['ноофен', 'для', 'какой', 'болезнь'],\n",
       "  ['маус', 'хаус', 'спб']],\n",
       " [['A=pl', 'S', 'A=m', 'S', 'S'],\n",
       "  ['NUM=ciph', 'V', 'S', 'NUM=ciph'],\n",
       "  ['S', 'S', 'PR', 'S', 'S'],\n",
       "  ['V', 'PR', 'A-PRO=pl', 'A=f'],\n",
       "  ['NONLEX', 'NONLEX', 'NONLEX']],\n",
       " [['сбербанк', 'в', 'кунцево', 'плаза'],\n",
       "  ['торт', 'дикий', 'вишня'],\n",
       "  ['тася', 'кривун', 'танец', 'на', 'тнт'],\n",
       "  ['рбт', 'ру'],\n",
       "  ['toplü', 'vay', 'sexx']],\n",
       " [['V', 'PR', 'S', 'S'],\n",
       "  ['S', 'A=f', 'S'],\n",
       "  ['S', 'S', 'S', 'PR', 'S'],\n",
       "  ['V', 'S'],\n",
       "  ['NONLEX', 'NONLEX', 'NONLEX']],\n",
       " 51353,\n",
       " 21174)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/requests.uniq.train'\n",
    "train_lem = read_queries_with_lemmatization(path)\n",
    "path = 'data/requests.uniq.test'\n",
    "test_lem = read_queries_with_lemmatization(path)\n",
    "train_lem[0][:5], train_lem[1][:5], test_lem[0][:5], test_lem[1][:5], len(train_lem[0]), len(test_lem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " array([0.12185658, 0.16966756, 0.20326518, 0.23018925, 0.2515358 ,\n",
       "        0.27062838, 0.28792218, 0.30358516, 0.31885922, 0.32964299]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words = Counter()\n",
    "\n",
    "for d in [train_lem[0]]:\n",
    "    for q in d:\n",
    "        for word in q:\n",
    "            count_words[word] += 1\n",
    "        \n",
    "freq, counts = np.unique(np.array(list(count_words.values())), return_counts=True) \n",
    "p = counts * freq \n",
    "p = p / p.sum()\n",
    "p = np.cumsum(p)\n",
    "freq[:10], p[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_2 = KeyedVectors.load_word2vec_format(\"ft_native_300_ru_wiki_lenta_lower_case.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A', 'A-PRO', 'A-PRO=f', 'A-PRO=m', 'A-PRO=n', 'A-PRO=pl',\n",
       "        'A-PRO=sg', 'A=brev', 'A=comp', 'A=comp2', 'A=f', 'A=m', 'A=n',\n",
       "        'A=pl', 'A=sg', 'ADV', 'ADV-PRO', 'ADV-PRO=abbr', 'ADV-PRO=comp',\n",
       "        'ADV-PRO=distort', 'ADV=abbr', 'ADV=comp', 'ADV=comp2',\n",
       "        'ANUM=ciph', 'ANUM=f', 'ANUM=m', 'ANUM=n', 'ANUM=pl', 'ANUM=sg',\n",
       "        'CONJ', 'INIT=abbr', 'INTJ', 'INTJ=distort', 'NONLEX',\n",
       "        'NONLEX=abbr', 'NUM', 'NUM=acc', 'NUM=ciph', 'NUM=comp', 'NUM=dat',\n",
       "        'NUM=f', 'NUM=gen', 'NUM=ins', 'NUM=loc', 'NUM=m', 'NUM=n',\n",
       "        'NUM=nom', 'PARENTH', 'PART', 'PR', 'PRAEDIC', 'PRAEDIC-PRO',\n",
       "        'PRAEDIC=comp', 'S', 'S-PRO', 'S-PRO=acc', 'S-PRO=dat',\n",
       "        'S-PRO=gen', 'S-PRO=ins', 'S-PRO=loc', 'S-PRO=n=sg', 'S-PRO=pl',\n",
       "        'S=m', 'V'], dtype='<U32'), 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = np.unique(np.hstack(train_lem[1]))\n",
    "tmp1 = np.unique(np.hstack(test_lem[1]))\n",
    "tmp = np.hstack([tmp, tmp1])\n",
    "tmp = np.unique(tmp)\n",
    "tmp, len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = tmp\n",
    "tags_to_ind = {}\n",
    "ind = 0\n",
    "for t in tags:\n",
    "    tags_to_ind[t] = ind\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сетки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* аддитивный attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_n_tokens(emb):\n",
    "    n_tokens = 0\n",
    "    for word in count_words.keys():\n",
    "        if word in emb.vocab and count_words[word] >= 3:\n",
    "            n_tokens += 1\n",
    "    return n_tokens + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_features(emb, emb_size, ind_to_word, batch_x, batch_x_tags):\n",
    "    to_emb = np.zeros((len(batch_x), len(batch_x[0])+1, emb_size + len(tags)))\n",
    "    for i in range(len(batch_x)):\n",
    "        to_emb[i][0] = np.ones(emb_size + len(tags))\n",
    "        for j in range(len(batch_x[i])):\n",
    "            if batch_x[i][j] != pad_id:\n",
    "                to_emb[i][j+1][:emb_size] = emb[ind_to_word[batch_x[i][j]]]\n",
    "                if batch_x_tags[i][j] >= 0:\n",
    "                    to_emb[i][j+1][emb_size + batch_x_tags[i][j]] = 1\n",
    "    return to_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Архитектуры сетей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, emb, ind_to_word, emb_size=300, lstm_units=256):\n",
    "        super(self.__class__, self).__init__()\n",
    "        n_tokens = calculate_n_tokens(emb)\n",
    "        self.lstm = nn.LSTM(emb_size + len(tags), lstm_units, batch_first=True)\n",
    "        self.logits = nn.Linear(lstm_units, n_tokens) \n",
    "        self.emb = emb\n",
    "        self.emb_size = emb_size\n",
    "        self.ind_to_word = ind_to_word\n",
    "        \n",
    "    def forward(self, batch_x, batch_x_tags):\n",
    "        input_emb = transform_to_features(self.emb, self.emb_size, self.ind_to_word, batch_x, batch_x_tags)\n",
    "        input_emb = torch.tensor(input_emb, dtype=torch.float32)\n",
    "        lstm_out = self.lstm(input_emb)\n",
    "        logits = self.logits(lstm_out[0])\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWithAttention(nn.Module):\n",
    "    def __init__(self, emb, ind_to_word, emb_size=300, lstm_units=256, hid_size=256):\n",
    "        super(self.__class__, self).__init__()\n",
    "        n_tokens = calculate_n_tokens(emb)\n",
    "        self.lstm = nn.LSTM(emb_size + len(tags), lstm_units, batch_first=True)\n",
    "        self.linear_lstm = nn.Linear(lstm_units, hid_size)\n",
    "        self.linear_out_lstm = nn.Linear(lstm_units, hid_size)\n",
    "        self.final_linear = nn.Linear(hid_size, 1)\n",
    "        self.logits = nn.Linear(hid_size, n_tokens)\n",
    "        self.emb = emb\n",
    "        self.emb_size = emb_size\n",
    "        self.ind_to_word = ind_to_word\n",
    "        \n",
    "    def forward(self, batch_x, batch_x_tags):\n",
    "        input_emb = transform_to_features(self.emb, self.emb_size, self.ind_to_word, batch_x, batch_x_tags)\n",
    "        input_emb = torch.tensor(input_emb, dtype=torch.float32)\n",
    "        lstm_out = self.lstm(input_emb)\n",
    "        #lstm_out = lstm_out[0][1:]\n",
    "        \n",
    "        \n",
    "        lstm_out_linear = self.linear_out_lstm(lstm_out[0])\n",
    "        lstm_linear = self.linear_lstm(lstm_out[0])\n",
    "        pre_logits = torch.zeros_like(lstm_out[0])\n",
    "        pre_logits[:, 0, :] = lstm_out[0][:, 0, :]\n",
    "        pre_logits[:, 1, :] = lstm_out[0][:, 1, :]\n",
    "        \n",
    "        mask = np.array([batch_x == pad_id], dtype=int)[0]\n",
    "        mask = torch.tensor(mask, dtype=torch.float32)\n",
    "        #print(mask.shape)\n",
    "        \n",
    "        for i in range(2, pre_logits.shape[1]):\n",
    "            to_add = lstm_out_linear[:, i, :]\n",
    "            basic = lstm_linear[:, 1:i+1, :]\n",
    "            to_add = to_add.reshape(pre_logits.shape[0], 1, pre_logits.shape[2])\n",
    "            tmp = basic + to_add\n",
    "            tmp = torch.tanh(tmp)\n",
    "            tmp = self.final_linear(tmp)\n",
    "            tmp = tmp.reshape(tmp.shape[0], tmp.shape[1])\n",
    "            tmp = F.softmax(tmp, dim=1)\n",
    "            #print(tmp.shape)\n",
    "            #print(mask.shape)\n",
    "            mask = np.array([batch_x == pad_id], dtype=int)[0][:, :i]\n",
    "            mask[:, -1] = np.ones(mask.shape[0])\n",
    "            mask = torch.tensor(mask, dtype=torch.float32)\n",
    "            \n",
    "            tmp = tmp * mask\n",
    "            tmp = tmp / torch.sum(tmp, dim=1).reshape(-1, 1)\n",
    "            tmp = tmp.reshape(tmp.shape[0], tmp.shape[1], 1)\n",
    "            pre_logits[:, i, :] = torch.sum(tmp * lstm_out[0][:, 1:i+1, :], dim=1)\n",
    "        \n",
    "        logits = self.logits(pre_logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = '#PAD#'\n",
    "pad_id = 0\n",
    "\n",
    "def construct_vocab(emb, count_words):\n",
    "    word_to_ind = dict()\n",
    "    word_to_ind['#PAD#'] = 0\n",
    "    ind_to_word = ['#PAD#', ]\n",
    "    \n",
    "    count = 1\n",
    "    for word in count_words.keys():\n",
    "        if count_words[word] >= 3 and word in emb.vocab:\n",
    "            ind_to_word.append(word)\n",
    "            word_to_ind[word] = count\n",
    "            count += 1\n",
    "    return ind_to_word, word_to_ind\n",
    "\n",
    "\n",
    "def as_matrix(sequences, tags, word_to_ind, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    max_len = max_len or max(map(len,sequences))\n",
    "    \n",
    "    matrix = np.zeros((2, len(sequences), max_len), dtype=int)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        for j, word in enumerate(seq[:max_len]):\n",
    "            if word in word_to_ind.keys():\n",
    "                matrix[0][i][j] = word_to_ind[word]\n",
    "                matrix[1][i][j] = tags_to_ind[tags[i][j]]\n",
    "            else:\n",
    "                matrix[0][i][j] = pad_id\n",
    "                matrix[1][i][j] = -1\n",
    "        for j in range(max_len, len(seq)):\n",
    "            matrix[0][i][j] = pad_id\n",
    "            matrix[1][i][j] = -1\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_word, word_to_ind = construct_vocab(emb_2, count_words)\n",
    "network = NetWithAttention(emb_2, ind_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(network, batch):\n",
    "    \"\"\"\n",
    "    use scalar crossentropy loss (neg llh) loss \n",
    "    \"\"\"\n",
    "    batch_x = batch[0]\n",
    "    batch_tags = batch[1]\n",
    "    batch_x = np.array(batch_x)\n",
    "    batch_tags = np.array(batch_tags)\n",
    "\n",
    "    batch_x_inp = batch_x[:, :-1]\n",
    "    batch_x_next = batch_x[:, 1:]\n",
    "    batch_tags_inp = batch_tags[:, :-1]\n",
    "    batch_tags_next = batch_tags[:, 1:]\n",
    "    \n",
    "    logits_for_next = network.forward(batch_x_inp, batch_tags_inp)\n",
    "    logits_for_next = logits_for_next[:, 1:]\n",
    "    \n",
    "    answers = torch.argmax(logits_for_next, dim=-1).numpy()\n",
    "    logits_for_next = logits_for_next.contiguous()\n",
    "    logits_for_next = logits_for_next.view(-1, logits_for_next.shape[-1])\n",
    "    \n",
    "    accr = np.array([answers == batch_x_next]) * np.array([answers != pad_id])\n",
    "    accr = accr.sum()\n",
    "    to_div = np.sum(np.array([batch_x_next != pad_id]))\n",
    "    batch_x_next = torch.tensor(batch_x_next, dtype=torch.int64)\n",
    "    batch_x_next = batch_x_next.view(-1)\n",
    "    \n",
    "    loss = F.cross_entropy(logits_for_next, batch_x_next, ignore_index=pad_id, reduction='mean')\n",
    "    \n",
    "    \n",
    "    return loss, accr, to_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "def generate_batch(train, batch_size, word_to_ind, max_len=None):\n",
    "    random_x = np.random.randint(0, len(train[0]), size=batch_size)\n",
    "    batch_x = []\n",
    "    batch_tags = []\n",
    "    for x in random_x:\n",
    "        batch_x.append(train[0][x])\n",
    "        batch_tags.append(train[1][x])\n",
    "    return as_matrix(batch_x, batch_tags, word_to_ind, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "n_epochs = 20 \n",
    "n_batches_per_epoch = 400  \n",
    "n_validation_batches = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:55<00:00,  1.88it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, train loss: 7.423060523271561, val loss: 7.038127017021179\n",
      "\n",
      "Epoch: 0, train accr: 0.05640062682373284, val accr: 0.07788437710199313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [04:19<00:00,  1.87it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, train loss: 6.594546213150024, val loss: 6.531922671198845\n",
      "\n",
      "Epoch: 1, train accr: 0.11072340539312023, val accr: 0.10850409119518847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [04:33<00:00,  1.60it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, train loss: 6.104903918504715, val loss: 6.355370584130287\n",
      "\n",
      "Epoch: 2, train accr: 0.1335185135244465, val accr: 0.12147528680175834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [04:27<00:00,  1.94it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3, train loss: 5.768276606798172, val loss: 6.197636517882347\n",
      "\n",
      "Epoch: 3, train accr: 0.14809663349222854, val accr: 0.1302777388132978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:49<00:00,  1.93it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4, train loss: 5.478484307527542, val loss: 6.077467900514603\n",
      "\n",
      "Epoch: 4, train accr: 0.16635284376961393, val accr: 0.13939157842547012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:37<00:00,  2.28it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5, train loss: 5.223425855636597, val loss: 6.061522600054741\n",
      "\n",
      "Epoch: 5, train accr: 0.18128843850512064, val accr: 0.14998230088495576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:37<00:00,  1.94it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6, train loss: 5.033553264141083, val loss: 6.016300585865975\n",
      "\n",
      "Epoch: 6, train accr: 0.19589634858224078, val accr: 0.1527566842086674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:40<00:00,  1.33it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7, train loss: 4.848545799255371, val loss: 6.030133962631226\n",
      "\n",
      "Epoch: 7, train accr: 0.21071012805587894, val accr: 0.15863623555931247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:47<00:00,  1.62it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8, train loss: 4.637233272194862, val loss: 5.978240105509758\n",
      "\n",
      "Epoch: 8, train accr: 0.22795453016748504, val accr: 0.15952150710934423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:44<00:00,  1.42it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9, train loss: 4.4731349092721935, val loss: 6.013766032457352\n",
      "\n",
      "Epoch: 9, train accr: 0.24753330543820104, val accr: 0.15749294105343883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:47<00:00,  1.90it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10, train loss: 4.340551814436912, val loss: 6.031679448485375\n",
      "\n",
      "Epoch: 10, train accr: 0.2594030412121863, val accr: 0.15970196464344708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:34<00:00,  1.64it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11, train loss: 4.178167462348938, val loss: 6.010131880640984\n",
      "\n",
      "Epoch: 11, train accr: 0.2762568442010951, val accr: 0.15855325412680055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:52<00:00,  2.24it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12, train loss: 4.044670078754425, val loss: 6.038313618302345\n",
      "\n",
      "Epoch: 12, train accr: 0.2901517589017589, val accr: 0.16670189530050025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:29<00:00,  2.10it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13, train loss: 3.9076805233955385, val loss: 6.103361284732818\n",
      "\n",
      "Epoch: 13, train accr: 0.30927472289515356, val accr: 0.15643564356435644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:38<00:00,  1.57it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14, train loss: 3.7983185827732084, val loss: 6.087379065155983\n",
      "\n",
      "Epoch: 14, train accr: 0.3216994621093484, val accr: 0.16348541829276947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:51<00:00,  2.05it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15, train loss: 3.6559036004543306, val loss: 6.134150323271752\n",
      "\n",
      "Epoch: 15, train accr: 0.3420181913169281, val accr: 0.16439474618388356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:37<00:00,  1.94it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16, train loss: 3.544307135939598, val loss: 6.165590533614159\n",
      "\n",
      "Epoch: 16, train accr: 0.35751057303841427, val accr: 0.16379249166134413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:50<00:00,  1.82it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17, train loss: 3.4641764444112777, val loss: 6.1288181185722355\n",
      "\n",
      "Epoch: 17, train accr: 0.36971964131374246, val accr: 0.16460630750860433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:35<00:00,  2.33it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18, train loss: 3.365718601942062, val loss: 6.159314242005348\n",
      "\n",
      "Epoch: 18, train accr: 0.38398104265402844, val accr: 0.16759638469142776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:39<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19, train loss: 3.2709632605314254, val loss: 6.236696863174439\n",
      "\n",
      "Epoch: 19, train accr: 0.40104025205062743, val accr: 0.16279069767441862\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "\n",
    "ind_to_word, word_to_ind = construct_vocab(emb_2, count_words)\n",
    "network = NetWithAttention(emb_2, ind_to_word)\n",
    "opt = Adam(network.parameters())\n",
    "\n",
    "train_loss, val_loss, train_accr, val_accr = [], [], [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss_=0\n",
    "    train_accr_=0\n",
    "    to_div = 0\n",
    "    network.train(True)\n",
    "    for _ in tqdm(range(n_batches_per_epoch)):\n",
    "        \n",
    "        loss_t, accr_t, to_div_t = compute_loss(network, generate_batch(train_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        loss_t.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        train_loss_ += loss_t.item()\n",
    "        train_accr_ += accr_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    train_loss_ /= n_batches_per_epoch\n",
    "    #train_accr_ /= n_batches_per_epoch\n",
    "    train_accr_ /= to_div\n",
    "    \n",
    "    val_loss_=0\n",
    "    val_accr_=0\n",
    "    to_div = 0\n",
    "    network.train(False)\n",
    "    for _ in range(n_validation_batches):\n",
    "        loss_t, accr_t, to_div_t = compute_loss(network, generate_batch(test_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        val_loss_ += loss_t.item()\n",
    "        val_accr_ += accr_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    val_loss_ /= n_validation_batches\n",
    "    #val_accr_ /= n_validation_batches\n",
    "    val_accr_ /= to_div\n",
    "    \n",
    "    train_loss.append(train_loss_)\n",
    "    val_loss.append(val_loss_)\n",
    "    train_accr.append(train_accr_)\n",
    "    val_accr.append(val_accr_)\n",
    "    \n",
    "    print('\\nEpoch: {}, train loss: {}, val loss: {}'.format(epoch, train_loss_, val_loss_))\n",
    "    print('\\nEpoch: {}, train accr: {}, val accr: {}'.format(epoch, train_accr_, val_accr_))\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), 'additive_attention.pwf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accr(network, batch):\n",
    "    batch_x = batch[0]\n",
    "    batch_tag = batch[1]\n",
    "    \n",
    "    batch_x = np.array(batch_x)\n",
    "    batch_tag = np.array(batch_tag)\n",
    "    batch_x_inp = batch_x[:, :-1]\n",
    "    batch_x_next = batch_x[:, 1:]\n",
    "    batch_tag_inp = batch_tag[:, :-1]\n",
    "    batch_tag_next = batch_tag[:, 1:]\n",
    "    \n",
    "    logits_for_next = network.forward(batch_x_inp, batch_tag_inp)\n",
    "    logits_for_next = logits_for_next[:, 1:]\n",
    "    \n",
    "    answers = torch.argmax(logits_for_next, dim=-1).numpy()\n",
    "    \n",
    "    accr = np.array([answers == batch_x_next]) * np.array([answers != pad_id])\n",
    "    accr = accr[0]\n",
    "    accr = accr.sum(axis=0)\n",
    "    to_divide = np.array([batch_x_next != pad_id])[0].sum(axis=0)\n",
    "    \n",
    "    return accr, to_divide\n",
    "\n",
    "def get_batch(data, left, right, batch_size, word_to_ind, max_len=None):\n",
    "    slice_x = np.arange(left, right, 1)\n",
    "    batch_x = []\n",
    "    batch_tag = []\n",
    "    for x in slice_x:\n",
    "        batch_x.append(data[0][x])\n",
    "        batch_tag.append(data[1][x])\n",
    "    return as_matrix(batch_x, batch_tag, word_to_ind, max_len)\n",
    "\n",
    "def try_lengthes(data):\n",
    "    accr = np.zeros(np.max(list(map(len, data[0]))))\n",
    "    to_div = np.zeros(np.max(list(map(len, data[0]))))\n",
    "    \n",
    "    for _ in tqdm_notebook(range(0, len(data[0])-batch_size, batch_size)):\n",
    "        accr_t, div_t = compute_accr(network, get_batch(data, _, _+batch_size, batch_size, word_to_ind))\n",
    "        accr[:len(accr_t)] += accr_t\n",
    "        to_div[:len(div_t)] += div_t\n",
    "    eps = 1\n",
    "    return accr / (to_div + eps), accr.sum() / to_div.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_pad(data):\n",
    "    to_pad = 0\n",
    "    all_ = 0\n",
    "    for x in data:\n",
    "        for word in x:\n",
    "            all_ += 1\n",
    "            if word not in word_to_ind.keys():\n",
    "                to_pad += 1\n",
    "    return to_pad / all_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a16fda1d46343c1a3de7438450a2958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=802), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.22727977, 0.34278654, 0.47388723, 0.52354379, 0.56286934,\n",
       "        0.56820909, 0.57379249, 0.58333333, 0.54569362, 0.55749129]),\n",
       " 0.40412957534357097)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "on_train, all_accr = try_lengthes(train_lem)\n",
    "on_train[:10], all_accr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764995a187054baea1e664c389dfd456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=330), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.14205298, 0.14598705, 0.17501215, 0.18585638, 0.19293589,\n",
       "        0.19933222, 0.19914347, 0.19434307, 0.14467409, 0.10951009]),\n",
       " 0.16324087691097508)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "on_test, all_accr = try_lengthes(test_lem)\n",
    "on_test[:10], all_accr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* attention с cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWithAttentionCosine(nn.Module):\n",
    "    def __init__(self, emb, ind_to_word, emb_size=300, lstm_units=256, hid_size=256):\n",
    "        super(self.__class__, self).__init__()\n",
    "        n_tokens = calculate_n_tokens(emb)\n",
    "        self.lstm = nn.LSTM(emb_size + len(tags), lstm_units, batch_first=True)\n",
    "        self.logits = nn.Linear(hid_size, n_tokens)\n",
    "        self.emb = emb\n",
    "        self.emb_size = emb_size\n",
    "        self.ind_to_word = ind_to_word\n",
    "        \n",
    "    def forward(self, batch_x, batch_x_tags):\n",
    "        input_emb = transform_to_features(self.emb, self.emb_size, self.ind_to_word, batch_x, batch_x_tags)\n",
    "        input_emb = torch.tensor(input_emb, dtype=torch.float32)\n",
    "        lstm_out = self.lstm(input_emb)        \n",
    "        \n",
    "        pre_logits = torch.zeros_like(lstm_out[0])\n",
    "        pre_logits[:, 0, :] = lstm_out[0][:, 0, :]\n",
    "        pre_logits[:, 1, :] = lstm_out[0][:, 1, :]\n",
    "        \n",
    "        for i in range(2, pre_logits.shape[1]):\n",
    "            current = lstm_out[0][:, i, :]\n",
    "            previous = lstm_out[0][:, 1:i+1, :]\n",
    "            current = current.reshape(pre_logits.shape[0], 1, pre_logits.shape[2])\n",
    "            cosine = torch.sum(previous * current, dim=-1) / torch.sum(previous * previous, dim=-1)\n",
    "            cosine /= torch.sum(current * current)\n",
    "            cosine = F.softmax(cosine, dim=1)\n",
    "            \n",
    "            mask = np.array([batch_x == pad_id], dtype=int)[0][:, :i]\n",
    "            mask[:, -1] = np.ones(mask.shape[0])\n",
    "            mask = torch.tensor(mask, dtype=torch.float32)\n",
    "            \n",
    "            tmp = cosine * mask\n",
    "            tmp = tmp / torch.sum(tmp, dim=1).reshape(-1, 1)\n",
    "            tmp = tmp.reshape(tmp.shape[0], tmp.shape[1], 1)\n",
    "            pre_logits[:, i, :] = torch.sum(tmp * lstm_out[0][:, 1:i+1, :], dim=1)\n",
    "        \n",
    "        logits = self.logits(pre_logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:39<00:00,  2.06it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, train loss: 7.44505086183548, val loss: 7.1137505799531935\n",
      "\n",
      "Epoch: 0, train accr: 0.05662855687651624, val accr: 0.07278391390540924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:11<00:00,  2.30it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, train loss: 6.6961684632301335, val loss: 6.67335011959076\n",
      "\n",
      "Epoch: 1, train accr: 0.1010148849797023, val accr: 0.10251135073779796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:12<00:00,  2.25it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, train loss: 6.236177433729171, val loss: 6.43335530757904\n",
      "\n",
      "Epoch: 2, train accr: 0.12295665489126785, val accr: 0.11792368805443727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:10<00:00,  2.23it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3, train loss: 5.887610920667648, val loss: 6.2970844358205795\n",
      "\n",
      "Epoch: 3, train accr: 0.1419347043977877, val accr: 0.12405333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:13<00:00,  2.35it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4, train loss: 5.630113972425461, val loss: 6.220975038409233\n",
      "\n",
      "Epoch: 4, train accr: 0.15478319327731094, val accr: 0.1336074714245888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:13<00:00,  2.07it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5, train loss: 5.417030644416809, val loss: 6.17641467154026\n",
      "\n",
      "Epoch: 5, train accr: 0.1676844852169702, val accr: 0.13669139568744368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:18<00:00,  2.15it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6, train loss: 5.174362083673477, val loss: 6.178724017739296\n",
      "\n",
      "Epoch: 6, train accr: 0.18613872068402812, val accr: 0.14180086026092212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:24<00:00,  1.96it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7, train loss: 5.0053264272212985, val loss: 6.099540641903877\n",
      "\n",
      "Epoch: 7, train accr: 0.20013222516055912, val accr: 0.1474485480687905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:09<00:00,  1.98it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8, train loss: 4.83504567027092, val loss: 6.105298948287964\n",
      "\n",
      "Epoch: 8, train accr: 0.2127192387974735, val accr: 0.1495208568207441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:10<00:00,  2.06it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9, train loss: 4.647806782126427, val loss: 6.073650851845741\n",
      "\n",
      "Epoch: 9, train accr: 0.23155523591114488, val accr: 0.15241282141599155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:27<00:00,  2.35it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10, train loss: 4.488833258748055, val loss: 6.0926534056663515\n",
      "\n",
      "Epoch: 10, train accr: 0.2483433048050868, val accr: 0.15284524635669675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:09<00:00,  2.08it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11, train loss: 4.367524445056915, val loss: 6.085264527797699\n",
      "\n",
      "Epoch: 11, train accr: 0.25973675693170784, val accr: 0.15710855286390282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:23<00:00,  2.19it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12, train loss: 4.252106469869614, val loss: 6.086110788583755\n",
      "\n",
      "Epoch: 12, train accr: 0.2699989262321486, val accr: 0.15500281056773468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:14<00:00,  1.52it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13, train loss: 4.136816199421883, val loss: 6.092726942896843\n",
      "\n",
      "Epoch: 13, train accr: 0.2853014261019879, val accr: 0.15868284471875438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:20<00:00,  1.65it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14, train loss: 3.992578672170639, val loss: 6.15544844865799\n",
      "\n",
      "Epoch: 14, train accr: 0.3023696682464455, val accr: 0.15538369177525868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:24<00:00,  2.09it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15, train loss: 3.867003793120384, val loss: 6.12329578101635\n",
      "\n",
      "Epoch: 15, train accr: 0.31621807770740207, val accr: 0.15921052631578947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:22<00:00,  1.14it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16, train loss: 3.7838563936948777, val loss: 6.206732812523842\n",
      "\n",
      "Epoch: 16, train accr: 0.3294041398306801, val accr: 0.15472139515099959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:29<00:00,  1.92it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17, train loss: 3.6661137396097185, val loss: 6.205356431007385\n",
      "\n",
      "Epoch: 17, train accr: 0.34507799892415275, val accr: 0.16134695740721233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:08<00:00,  2.27it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18, train loss: 3.571841896176338, val loss: 6.259359449148178\n",
      "\n",
      "Epoch: 18, train accr: 0.35601102076473357, val accr: 0.1579226660062971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:24<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19, train loss: 3.4841410970687865, val loss: 6.270016765594482\n",
      "\n",
      "Epoch: 19, train accr: 0.3691182446160097, val accr: 0.16115981119352663\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "\n",
    "ind_to_word, word_to_ind = construct_vocab(emb_2, count_words)\n",
    "network = NetWithAttentionCosine(emb_2, ind_to_word)\n",
    "opt = Adam(network.parameters())\n",
    "\n",
    "train_loss, val_loss, train_accr, val_accr = [], [], [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss_=0\n",
    "    train_accr_=0\n",
    "    to_div = 0\n",
    "    network.train(True)\n",
    "    for _ in tqdm(range(n_batches_per_epoch)):\n",
    "        \n",
    "        loss_t, accr_t, to_div_t = compute_loss(network, generate_batch(train_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        loss_t.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        train_loss_ += loss_t.item()\n",
    "        train_accr_ += accr_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    train_loss_ /= n_batches_per_epoch\n",
    "    #train_accr_ /= n_batches_per_epoch\n",
    "    train_accr_ /= to_div\n",
    "    \n",
    "    val_loss_=0\n",
    "    val_accr_=0\n",
    "    to_div = 0\n",
    "    network.train(False)\n",
    "    for _ in range(n_validation_batches):\n",
    "        loss_t, accr_t, to_div_t = compute_loss(network, generate_batch(test_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        val_loss_ += loss_t.item()\n",
    "        val_accr_ += accr_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    val_loss_ /= n_validation_batches\n",
    "    #val_accr_ /= n_validation_batches\n",
    "    val_accr_ /= to_div\n",
    "    \n",
    "    train_loss.append(train_loss_)\n",
    "    val_loss.append(val_loss_)\n",
    "    train_accr.append(train_accr_)\n",
    "    val_accr.append(val_accr_)\n",
    "    \n",
    "    print('\\nEpoch: {}, train loss: {}, val loss: {}'.format(epoch, train_loss_, val_loss_))\n",
    "    print('\\nEpoch: {}, train accr: {}, val accr: {}'.format(epoch, train_accr_, val_accr_))\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), 'cosine_attention.pwf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961de08dbdd2413a978f7499da874510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=802), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.22640145, 0.33578489, 0.43739364, 0.47390519, 0.49326986,\n",
       "        0.48579811, 0.48703041, 0.48782344, 0.45627876, 0.43902439]),\n",
       " 0.37205174407659414)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_train, all_accr = try_lengthes(train_lem)\n",
    "on_train[:10], all_accr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6393d501594dc9bd3cabb1b9cc9519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=330), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.14172185, 0.14365306, 0.17306757, 0.18476632, 0.18231931,\n",
       "        0.18764608, 0.17558887, 0.16970803, 0.14626391, 0.09510086]),\n",
       " 0.15946167789596088)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_test, all_accr = try_lengthes(test_lem)\n",
    "on_test[:10], all_accr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* attention с dot product similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWithAttentionDotProduct(nn.Module):\n",
    "    def __init__(self, emb, ind_to_word, emb_size=300, lstm_units=256, hid_size=256):\n",
    "        super(self.__class__, self).__init__()\n",
    "        n_tokens = calculate_n_tokens(emb)\n",
    "        self.lstm = nn.LSTM(emb_size + len(tags), lstm_units, batch_first=True)\n",
    "        self.logits = nn.Linear(hid_size, n_tokens)\n",
    "        self.emb = emb\n",
    "        self.emb_size = emb_size\n",
    "        self.ind_to_word = ind_to_word\n",
    "        \n",
    "    def forward(self, batch_x, batch_x_tags):\n",
    "        input_emb = transform_to_features(self.emb, self.emb_size, self.ind_to_word, batch_x, batch_x_tags)\n",
    "        input_emb = torch.tensor(input_emb, dtype=torch.float32)\n",
    "        lstm_out = self.lstm(input_emb)        \n",
    "        \n",
    "        pre_logits = torch.zeros_like(lstm_out[0])\n",
    "        pre_logits[:, 0, :] = lstm_out[0][:, 0, :]\n",
    "        pre_logits[:, 1, :] = lstm_out[0][:, 1, :]\n",
    "        \n",
    "        for i in range(2, pre_logits.shape[1]):\n",
    "            current = lstm_out[0][:, i, :]\n",
    "            previous = lstm_out[0][:, 1:i+1, :]\n",
    "            current = current.reshape(pre_logits.shape[0], 1, pre_logits.shape[2])\n",
    "            dot_product = torch.sum(previous * current, dim=-1)\n",
    "            dot_product = F.softmax(dot_product, dim=1)\n",
    "            \n",
    "            mask = np.array([batch_x == pad_id], dtype=int)[0][:, :i]\n",
    "            mask[:, -1] = np.ones(mask.shape[0])\n",
    "            mask = torch.tensor(mask, dtype=torch.float32)\n",
    "            \n",
    "            tmp = dot_product * mask\n",
    "            tmp = tmp / torch.sum(tmp, dim=1).reshape(-1, 1)\n",
    "            tmp = tmp.reshape(tmp.shape[0], tmp.shape[1], 1)\n",
    "            pre_logits[:, i, :] = torch.sum(tmp * lstm_out[0][:, 1:i+1, :], dim=1)\n",
    "        \n",
    "        logits = self.logits(pre_logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:29<00:00,  1.59s/it]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, train loss: 7.416083530187607, val loss: 7.038138619065284\n",
      "\n",
      "Epoch: 0, train accr: 0.05802608883139284, val accr: 0.08346372688477952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:20<00:00,  2.27it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, train loss: 6.5898543739318844, val loss: 6.519152516126633\n",
      "\n",
      "Epoch: 1, train accr: 0.11141763695619836, val accr: 0.11138875202365031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:15<00:00,  2.15it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, train loss: 6.10610211968422, val loss: 6.32130691409111\n",
      "\n",
      "Epoch: 2, train accr: 0.1343413112753407, val accr: 0.12266789393563918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:18<00:00,  1.39it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3, train loss: 5.750876413583756, val loss: 6.216240027546883\n",
      "\n",
      "Epoch: 3, train accr: 0.1520407891583908, val accr: 0.13323290358744394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:30<00:00,  2.22it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4, train loss: 5.495996385812759, val loss: 6.108094716072083\n",
      "\n",
      "Epoch: 4, train accr: 0.1652547492783782, val accr: 0.14129738957251584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:27<00:00,  2.25it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5, train loss: 5.2199262070655825, val loss: 6.037539073824883\n",
      "\n",
      "Epoch: 5, train accr: 0.18134526977982096, val accr: 0.15114578254509994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:11<00:00,  2.19it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6, train loss: 4.988677082061767, val loss: 6.045672821998596\n",
      "\n",
      "Epoch: 6, train accr: 0.19864235789699627, val accr: 0.15292818466799657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:12<00:00,  2.10it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7, train loss: 4.826058906316757, val loss: 5.987785187363625\n",
      "\n",
      "Epoch: 7, train accr: 0.21086780210867803, val accr: 0.15512416928996153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:10<00:00,  2.18it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8, train loss: 4.625342229604721, val loss: 6.016707813739776\n",
      "\n",
      "Epoch: 8, train accr: 0.23316446145139993, val accr: 0.1602275920202304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:15<00:00,  1.99it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9, train loss: 4.445227854847908, val loss: 6.0072618335485455\n",
      "\n",
      "Epoch: 9, train accr: 0.24838079849188716, val accr: 0.15843671170392895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:15<00:00,  2.45it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10, train loss: 4.286374972462654, val loss: 5.997842311859131\n",
      "\n",
      "Epoch: 10, train accr: 0.26692625877470727, val accr: 0.16398950131233594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:11<00:00,  1.88it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11, train loss: 4.163279265165329, val loss: 6.0592894673347475\n",
      "\n",
      "Epoch: 11, train accr: 0.28128586279989737, val accr: 0.1627637944331487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:16<00:00,  2.04it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12, train loss: 4.02643232345581, val loss: 6.039686298370361\n",
      "\n",
      "Epoch: 12, train accr: 0.29388512423362373, val accr: 0.1644576212068364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:23<00:00,  2.18it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13, train loss: 3.896793942451477, val loss: 6.106889122724533\n",
      "\n",
      "Epoch: 13, train accr: 0.31116321938789343, val accr: 0.16126767978099885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:17<00:00,  1.83it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14, train loss: 3.7756284737586974, val loss: 6.086659649014473\n",
      "\n",
      "Epoch: 14, train accr: 0.3285609795741453, val accr: 0.16556914393226718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:29<00:00,  1.82it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15, train loss: 3.651914670467377, val loss: 6.104388958215713\n",
      "\n",
      "Epoch: 15, train accr: 0.3412018906144497, val accr: 0.16692519213142495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:24<00:00,  1.93it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16, train loss: 3.541927777528763, val loss: 6.125961038470268\n",
      "\n",
      "Epoch: 16, train accr: 0.3553207729080464, val accr: 0.16136747326955542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:14<00:00,  2.16it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17, train loss: 3.4509879976511, val loss: 6.157786852121353\n",
      "\n",
      "Epoch: 17, train accr: 0.37248050511319175, val accr: 0.1617590688922187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:17<00:00,  2.34it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18, train loss: 3.3672933101654055, val loss: 6.181353515386581\n",
      "\n",
      "Epoch: 18, train accr: 0.37959298659833923, val accr: 0.16628101527179523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:14<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19, train loss: 3.2424461460113525, val loss: 6.271638941764832\n",
      "\n",
      "Epoch: 19, train accr: 0.40121446093215907, val accr: 0.16192755590483676\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "\n",
    "ind_to_word, word_to_ind = construct_vocab(emb_2, count_words)\n",
    "network = NetWithAttentionDotProduct(emb_2, ind_to_word)\n",
    "opt = Adam(network.parameters())\n",
    "\n",
    "train_loss, val_loss, train_accr, val_accr = [], [], [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss_=0\n",
    "    train_accr_=0\n",
    "    to_div = 0\n",
    "    network.train(True)\n",
    "    for _ in tqdm(range(n_batches_per_epoch)):\n",
    "        \n",
    "        loss_t, accr_t, to_div_t = compute_loss(network, generate_batch(train_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        loss_t.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        train_loss_ += loss_t.item()\n",
    "        train_accr_ += accr_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    train_loss_ /= n_batches_per_epoch\n",
    "    #train_accr_ /= n_batches_per_epoch\n",
    "    train_accr_ /= to_div\n",
    "    \n",
    "    val_loss_=0\n",
    "    val_accr_=0\n",
    "    to_div = 0\n",
    "    network.train(False)\n",
    "    for _ in range(n_validation_batches):\n",
    "        loss_t, accr_t, to_div_t = compute_loss(network, generate_batch(test_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        val_loss_ += loss_t.item()\n",
    "        val_accr_ += accr_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    val_loss_ /= n_validation_batches\n",
    "    #val_accr_ /= n_validation_batches\n",
    "    val_accr_ /= to_div\n",
    "    \n",
    "    train_loss.append(train_loss_)\n",
    "    val_loss.append(val_loss_)\n",
    "    train_accr.append(train_accr_)\n",
    "    val_accr.append(val_accr_)\n",
    "    \n",
    "    print('\\nEpoch: {}, train loss: {}, val loss: {}'.format(epoch, train_loss_, val_loss_))\n",
    "    print('\\nEpoch: {}, train accr: {}, val accr: {}'.format(epoch, train_accr_, val_accr_))\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), 'dotproduct_attention.pwf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d4928b6b9f4bd8b18f69d5d6cd1182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=802), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.22640145, 0.33978583, 0.47082404, 0.52184311, 0.5541694 ,\n",
       "        0.55914122, 0.57088551, 0.57420091, 0.5687048 , 0.51103368]),\n",
       " 0.40098969959390046)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_train, all_accr = try_lengthes(train_lem)\n",
    "on_train[:10], all_accr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fb996605ed46888a4ab2864763b2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=330), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.14172185, 0.1508056 , 0.17491492, 0.18190489, 0.19089424,\n",
       "        0.20133556, 0.19379015, 0.18613139, 0.12877583, 0.10086455]),\n",
       " 0.16308697287868942)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_test, all_accr = try_lengthes(test_lem)\n",
    "on_test[:10], all_accr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* location based attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWithAttentionLocbased(nn.Module):\n",
    "    def __init__(self, emb, ind_to_word, emb_size=300, lstm_units=256, hid_size=256):\n",
    "        super(self.__class__, self).__init__()\n",
    "        n_tokens = calculate_n_tokens(emb)\n",
    "        self.lstm = nn.LSTM(emb_size + len(tags), lstm_units, batch_first=True)\n",
    "        self.logits = nn.Linear(hid_size, n_tokens)\n",
    "        self.inner = nn.Linear(lstm_units, 1)\n",
    "        self.emb = emb\n",
    "        self.emb_size = emb_size\n",
    "        self.ind_to_word = ind_to_word\n",
    "        \n",
    "    def forward(self, batch_x, batch_x_tags):\n",
    "        input_emb = transform_to_features(self.emb, self.emb_size, self.ind_to_word, batch_x, batch_x_tags)\n",
    "        input_emb = torch.tensor(input_emb, dtype=torch.float32)\n",
    "        lstm_out = self.lstm(input_emb)        \n",
    "        \n",
    "        pre_logits = torch.zeros_like(lstm_out[0])\n",
    "        pre_logits[:, 0, :] = lstm_out[0][:, 0, :]\n",
    "        pre_logits[:, 1, :] = lstm_out[0][:, 1, :]\n",
    "        \n",
    "        for i in range(2, pre_logits.shape[1]):\n",
    "            current = lstm_out[0][:, i, :]\n",
    "            current = self.inner(current)\n",
    "            current = F.softmax(current, dim=1)\n",
    "            \n",
    "            mask = np.array([batch_x == pad_id], dtype=int)[0][:, :i]\n",
    "            mask[:, -1] = np.ones(mask.shape[0])\n",
    "            mask = torch.tensor(mask, dtype=torch.float32)\n",
    "            \n",
    "            tmp = current * mask\n",
    "            tmp = tmp / torch.sum(tmp, dim=1).reshape(-1, 1)\n",
    "            tmp = tmp.reshape(tmp.shape[0], tmp.shape[1], 1)\n",
    "            pre_logits[:, i, :] = torch.sum(tmp * lstm_out[0][:, 1:i+1, :], dim=1)\n",
    "        \n",
    "        logits = self.logits(pre_logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:14<00:00,  2.16it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0, train loss: 7.447025760412216, val loss: 7.115234318375587\n",
      "\n",
      "Epoch: 0, train accr: 0.055655706828822045, val accr: 0.068666057239294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:11<00:00,  2.21it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1, train loss: 6.730785636901856, val loss: 6.675900080800057\n",
      "\n",
      "Epoch: 1, train accr: 0.09917220789795088, val accr: 0.09547720669990316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:23<00:00,  1.74it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2, train loss: 6.216401575803757, val loss: 6.456563133001327\n",
      "\n",
      "Epoch: 2, train accr: 0.12674486564364645, val accr: 0.1163982683982684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:16<00:00,  2.31it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3, train loss: 5.895000921487808, val loss: 6.307088363170624\n",
      "\n",
      "Epoch: 3, train accr: 0.14418386491557222, val accr: 0.12609337316871244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:17<00:00,  2.15it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4, train loss: 5.621777420043945, val loss: 6.220817524194717\n",
      "\n",
      "Epoch: 4, train accr: 0.15472871112771322, val accr: 0.13327038746677858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:20<00:00,  2.03it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5, train loss: 5.404830946922302, val loss: 6.151641166210174\n",
      "\n",
      "Epoch: 5, train accr: 0.16867956537544937, val accr: 0.14225120061695937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:21<00:00,  1.66it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6, train loss: 5.185947972536087, val loss: 6.151007956266403\n",
      "\n",
      "Epoch: 6, train accr: 0.18437419894496837, val accr: 0.1418501893673727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:07<00:00,  2.31it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7, train loss: 4.970528242588043, val loss: 6.1207690834999084\n",
      "\n",
      "Epoch: 7, train accr: 0.20352290293710845, val accr: 0.14715449998251076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:21<00:00,  2.18it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8, train loss: 4.812678690552712, val loss: 6.095470517873764\n",
      "\n",
      "Epoch: 8, train accr: 0.21427996025885448, val accr: 0.14671612022813954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:16<00:00,  1.92it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9, train loss: 4.673326399922371, val loss: 6.081770867109299\n",
      "\n",
      "Epoch: 9, train accr: 0.2272511043153245, val accr: 0.15194751093522182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:16<00:00,  2.46it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10, train loss: 4.514206776618957, val loss: 6.050610202550888\n",
      "\n",
      "Epoch: 10, train accr: 0.24193199632412563, val accr: 0.15652850473900126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:18<00:00,  1.91it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11, train loss: 4.365518608093262, val loss: 6.067493364214897\n",
      "\n",
      "Epoch: 11, train accr: 0.25680583203314145, val accr: 0.1573266769793278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:30<00:00,  2.27it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12, train loss: 4.239488666057587, val loss: 6.0544316411018375\n",
      "\n",
      "Epoch: 12, train accr: 0.2719080299225077, val accr: 0.15548090523338048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:20<00:00,  2.04it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13, train loss: 4.110196410417557, val loss: 6.112796288728714\n",
      "\n",
      "Epoch: 13, train accr: 0.28842671423551985, val accr: 0.15614840989399292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:16<00:00,  2.13it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14, train loss: 3.9873586916923522, val loss: 6.166152790188789\n",
      "\n",
      "Epoch: 14, train accr: 0.30071155193790094, val accr: 0.15404192145912127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:14<00:00,  2.35it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15, train loss: 3.8687827450037005, val loss: 6.131808218359947\n",
      "\n",
      "Epoch: 15, train accr: 0.31547010386954416, val accr: 0.15707902820441216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:25<00:00,  2.11it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16, train loss: 3.792925373911858, val loss: 6.204553681612015\n",
      "\n",
      "Epoch: 16, train accr: 0.32246884945250553, val accr: 0.15393298059964727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:20<00:00,  2.08it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17, train loss: 3.657875906229019, val loss: 6.196912091970444\n",
      "\n",
      "Epoch: 17, train accr: 0.34223889596034035, val accr: 0.1590597659955729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:21<00:00,  2.31it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18, train loss: 3.6070441538095475, val loss: 6.2312178134918215\n",
      "\n",
      "Epoch: 18, train accr: 0.3490930716622064, val accr: 0.1564366998577525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [03:15<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19, train loss: 3.502924472093582, val loss: 6.266480302810669\n",
      "\n",
      "Epoch: 19, train accr: 0.36231185387540843, val accr: 0.156059377313917\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "\n",
    "ind_to_word, word_to_ind = construct_vocab(emb_2, count_words)\n",
    "network = NetWithAttentionLocbased(emb_2, ind_to_word)\n",
    "opt = Adam(network.parameters())\n",
    "\n",
    "train_loss, val_loss, train_accr, val_accr = [], [], [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss_=0\n",
    "    train_accr_=0\n",
    "    to_div = 0\n",
    "    network.train(True)\n",
    "    for _ in tqdm(range(n_batches_per_epoch)):\n",
    "        \n",
    "        loss_t, accr_t, to_div_t = compute_loss(network, generate_batch(train_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        loss_t.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        train_loss_ += loss_t.item()\n",
    "        train_accr_ += accr_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    train_loss_ /= n_batches_per_epoch\n",
    "    #train_accr_ /= n_batches_per_epoch\n",
    "    train_accr_ /= to_div\n",
    "    \n",
    "    val_loss_=0\n",
    "    val_accr_=0\n",
    "    to_div = 0\n",
    "    network.train(False)\n",
    "    for _ in range(n_validation_batches):\n",
    "        loss_t, accr_t, to_div_t = compute_loss(network, generate_batch(test_lem, batch_size, word_to_ind))\n",
    "        \n",
    "        val_loss_ += loss_t.item()\n",
    "        val_accr_ += accr_t.item()\n",
    "        to_div += to_div_t\n",
    "        \n",
    "    val_loss_ /= n_validation_batches\n",
    "    #val_accr_ /= n_validation_batches\n",
    "    val_accr_ /= to_div\n",
    "    \n",
    "    train_loss.append(train_loss_)\n",
    "    val_loss.append(val_loss_)\n",
    "    train_accr.append(train_accr_)\n",
    "    val_accr.append(val_accr_)\n",
    "    \n",
    "    print('\\nEpoch: {}, train loss: {}, val loss: {}'.format(epoch, train_loss_, val_loss_))\n",
    "    print('\\nEpoch: {}, train accr: {}, val accr: {}'.format(epoch, train_accr_, val_accr_))\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), 'locationbased_attention.pwf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8238d0b361a6420b9a6b7fc1eccd2598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=802), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.22913976, 0.34031537, 0.44196952, 0.46821854, 0.48711425,\n",
       "        0.4844646 , 0.49686941, 0.48363775, 0.45693623, 0.42973287]),\n",
       " 0.3735040206546002)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_train, all_accr = try_lengthes(train_lem)\n",
    "on_train[:10], all_accr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58c1b513bd04bf39a7624eb8bfa15e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=330), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.14099338, 0.14523415, 0.16752552, 0.17917972, 0.17741935,\n",
       "        0.18297162, 0.18254818, 0.17791971, 0.14626391, 0.08933718]),\n",
       " 0.15739252368412052)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "on_test, all_accr = try_lengthes(test_lem)\n",
    "on_test[:10], all_accr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
